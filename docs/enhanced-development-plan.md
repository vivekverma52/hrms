# HRMS Workforce Management System
## Enhanced Development Plan - Complete Implementation Guide

---

## Phase 1: Backend Foundation (Weeks 1-4)
**Budget: $45,000 | Team: 3 developers | Priority: CRITICAL**

### 1.1 PostgreSQL Database Implementation

#### 1.1.1 Advanced Database Schema Design
```sql
-- Enhanced Employee Management Schema
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pg_trgm";
CREATE EXTENSION IF NOT EXISTS "btree_gin";

-- Core employee table with enhanced fields
CREATE TABLE employees (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    employee_id VARCHAR(50) UNIQUE NOT NULL,
    name VARCHAR(255) NOT NULL,
    name_ar VARCHAR(255),
    trade VARCHAR(100) NOT NULL,
    nationality VARCHAR(100) NOT NULL,
    phone_number VARCHAR(20) NOT NULL,
    email VARCHAR(255),
    hourly_rate DECIMAL(10,2) NOT NULL CHECK (hourly_rate >= 18.00),
    actual_rate DECIMAL(10,2) NOT NULL CHECK (actual_rate > hourly_rate),
    project_id UUID REFERENCES projects(id),
    status employee_status DEFAULT 'active',
    skills JSONB DEFAULT '[]',
    certifications JSONB DEFAULT '[]',
    performance_rating INTEGER CHECK (performance_rating BETWEEN 0 AND 100),
    emergency_contact JSONB,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    created_by UUID REFERENCES users(id),
    last_modified_by UUID REFERENCES users(id)
);

-- Enhanced project management
CREATE TABLE projects (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    name VARCHAR(255) NOT NULL,
    client VARCHAR(255) NOT NULL,
    contractor VARCHAR(255) NOT NULL,
    location VARCHAR(255) NOT NULL,
    start_date DATE NOT NULL,
    end_date DATE NOT NULL,
    budget DECIMAL(15,2) NOT NULL,
    status project_status DEFAULT 'active',
    progress INTEGER DEFAULT 0 CHECK (progress BETWEEN 0 AND 100),
    description TEXT,
    requirements JSONB DEFAULT '[]',
    deliverables JSONB DEFAULT '[]',
    risk_level risk_level DEFAULT 'medium',
    profit_margin DECIMAL(5,2),
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Advanced attendance tracking with GPS and biometric support
CREATE TABLE attendance_records (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    employee_id UUID NOT NULL REFERENCES employees(id),
    project_id UUID REFERENCES projects(id),
    date DATE NOT NULL,
    clock_in_time TIMESTAMP WITH TIME ZONE,
    clock_out_time TIMESTAMP WITH TIME ZONE,
    hours_worked DECIMAL(4,2) NOT NULL DEFAULT 0,
    overtime_hours DECIMAL(4,2) DEFAULT 0,
    break_time DECIMAL(4,2) DEFAULT 0,
    late_arrival DECIMAL(4,2) DEFAULT 0,
    early_departure DECIMAL(4,2) DEFAULT 0,
    location_checkin POINT,
    location_checkout POINT,
    weather_conditions VARCHAR(100),
    biometric_verification BOOLEAN DEFAULT FALSE,
    photo_verification_url VARCHAR(500),
    supervisor_approval UUID REFERENCES users(id),
    notes TEXT,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    UNIQUE(employee_id, date)
);

-- Document management with version control
CREATE TABLE employee_documents (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    employee_id UUID NOT NULL REFERENCES employees(id),
    name VARCHAR(255) NOT NULL,
    document_type document_type NOT NULL,
    category document_category NOT NULL,
    file_name VARCHAR(255) NOT NULL,
    file_path VARCHAR(500) NOT NULL,
    file_size BIGINT NOT NULL,
    mime_type VARCHAR(100) NOT NULL,
    upload_date TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    uploaded_by UUID NOT NULL REFERENCES users(id),
    expiry_date DATE,
    is_confidential BOOLEAN DEFAULT FALSE,
    access_level access_level DEFAULT 'hr-only',
    version INTEGER DEFAULT 1,
    parent_document_id UUID REFERENCES employee_documents(id),
    tags TEXT[] DEFAULT '{}',
    metadata JSONB DEFAULT '{}',
    approval_status approval_status DEFAULT 'pending',
    approved_by UUID REFERENCES users(id),
    approved_at TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Financial calculations cache for performance
CREATE TABLE financial_calculations (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    employee_id UUID NOT NULL REFERENCES employees(id),
    project_id UUID REFERENCES projects(id),
    calculation_date DATE NOT NULL,
    regular_hours DECIMAL(4,2) NOT NULL,
    overtime_hours DECIMAL(4,2) DEFAULT 0,
    labor_cost DECIMAL(10,2) NOT NULL,
    revenue DECIMAL(10,2) NOT NULL,
    profit DECIMAL(10,2) NOT NULL,
    profit_margin DECIMAL(5,2) NOT NULL,
    effective_rate DECIMAL(10,2) NOT NULL,
    calculated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    UNIQUE(employee_id, project_id, calculation_date)
);

-- Audit trail for all operations
CREATE TABLE audit_logs (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    table_name VARCHAR(100) NOT NULL,
    record_id UUID NOT NULL,
    action audit_action NOT NULL,
    old_values JSONB,
    new_values JSONB,
    changed_by UUID REFERENCES users(id),
    changed_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    ip_address INET,
    user_agent TEXT,
    session_id VARCHAR(255)
);

-- Performance indexes
CREATE INDEX idx_employees_project_id ON employees(project_id) WHERE project_id IS NOT NULL;
CREATE INDEX idx_employees_status ON employees(status) WHERE status = 'active';
CREATE INDEX idx_attendance_employee_date ON attendance_records(employee_id, date DESC);
CREATE INDEX idx_attendance_project_date ON attendance_records(project_id, date DESC) WHERE project_id IS NOT NULL;
CREATE INDEX idx_documents_employee_expiry ON employee_documents(employee_id, expiry_date) WHERE expiry_date IS NOT NULL;
CREATE INDEX idx_financial_calc_lookup ON financial_calculations(employee_id, project_id, calculation_date DESC);
CREATE INDEX idx_audit_logs_table_record ON audit_logs(table_name, record_id, changed_at DESC);

-- Full-text search indexes
CREATE INDEX idx_employees_search ON employees USING gin(to_tsvector('english', name || ' ' || trade || ' ' || nationality));
CREATE INDEX idx_projects_search ON projects USING gin(to_tsvector('english', name || ' ' || client || ' ' || location));

-- Enum types
CREATE TYPE employee_status AS ENUM ('active', 'inactive', 'on-leave', 'terminated');
CREATE TYPE project_status AS ENUM ('active', 'hold', 'finished', 'cancelled');
CREATE TYPE risk_level AS ENUM ('low', 'medium', 'high', 'critical');
CREATE TYPE document_type AS ENUM ('passport', 'visa', 'iqama', 'national-id', 'contract', 'certificate', 'medical-report', 'training-certificate', 'other');
CREATE TYPE document_category AS ENUM ('personal', 'professional', 'legal', 'medical', 'training');
CREATE TYPE access_level AS ENUM ('public', 'hr-only', 'manager-only', 'restricted');
CREATE TYPE approval_status AS ENUM ('pending', 'approved', 'rejected');
CREATE TYPE audit_action AS ENUM ('INSERT', 'UPDATE', 'DELETE', 'LOGIN', 'LOGOUT');
```

#### 1.1.2 Advanced Database Features
```sql
-- Automated triggers for audit logging
CREATE OR REPLACE FUNCTION audit_trigger_function()
RETURNS TRIGGER AS $$
BEGIN
    IF TG_OP = 'DELETE' THEN
        INSERT INTO audit_logs (table_name, record_id, action, old_values, changed_by)
        VALUES (TG_TABLE_NAME, OLD.id, 'DELETE', row_to_json(OLD), current_setting('app.current_user_id', true)::UUID);
        RETURN OLD;
    ELSIF TG_OP = 'UPDATE' THEN
        INSERT INTO audit_logs (table_name, record_id, action, old_values, new_values, changed_by)
        VALUES (TG_TABLE_NAME, NEW.id, 'UPDATE', row_to_json(OLD), row_to_json(NEW), current_setting('app.current_user_id', true)::UUID);
        RETURN NEW;
    ELSIF TG_OP = 'INSERT' THEN
        INSERT INTO audit_logs (table_name, record_id, action, new_values, changed_by)
        VALUES (TG_TABLE_NAME, NEW.id, 'INSERT', row_to_json(NEW), current_setting('app.current_user_id', true)::UUID);
        RETURN NEW;
    END IF;
    RETURN NULL;
END;
$$ LANGUAGE plpgsql;

-- Apply audit triggers to all tables
CREATE TRIGGER employees_audit_trigger
    AFTER INSERT OR UPDATE OR DELETE ON employees
    FOR EACH ROW EXECUTE FUNCTION audit_trigger_function();

-- Automated financial calculations
CREATE OR REPLACE FUNCTION calculate_daily_financials()
RETURNS TRIGGER AS $$
DECLARE
    emp_record employees%ROWTYPE;
    labor_cost DECIMAL(10,2);
    revenue DECIMAL(10,2);
    profit DECIMAL(10,2);
    profit_margin DECIMAL(5,2);
    effective_rate DECIMAL(10,2);
BEGIN
    SELECT * INTO emp_record FROM employees WHERE id = NEW.employee_id;
    
    -- Calculate labor cost (what company pays)
    labor_cost := (NEW.hours_worked * emp_record.hourly_rate) + 
                  (NEW.overtime_hours * emp_record.hourly_rate * 1.5);
    
    -- Calculate revenue (what company bills)
    revenue := (NEW.hours_worked * emp_record.actual_rate) + 
               (NEW.overtime_hours * emp_record.actual_rate * 1.5);
    
    -- Calculate profit and margin
    profit := revenue - labor_cost;
    profit_margin := CASE WHEN revenue > 0 THEN (profit / revenue) * 100 ELSE 0 END;
    effective_rate := CASE WHEN (NEW.hours_worked + NEW.overtime_hours) > 0 
                      THEN revenue / (NEW.hours_worked + NEW.overtime_hours) 
                      ELSE 0 END;
    
    -- Insert or update financial calculation
    INSERT INTO financial_calculations (
        employee_id, project_id, calculation_date, regular_hours, overtime_hours,
        labor_cost, revenue, profit, profit_margin, effective_rate
    ) VALUES (
        NEW.employee_id, NEW.project_id, NEW.date, NEW.hours_worked, NEW.overtime_hours,
        labor_cost, revenue, profit, profit_margin, effective_rate
    ) ON CONFLICT (employee_id, project_id, calculation_date) 
    DO UPDATE SET
        regular_hours = EXCLUDED.regular_hours,
        overtime_hours = EXCLUDED.overtime_hours,
        labor_cost = EXCLUDED.labor_cost,
        revenue = EXCLUDED.revenue,
        profit = EXCLUDED.profit,
        profit_margin = EXCLUDED.profit_margin,
        effective_rate = EXCLUDED.effective_rate,
        calculated_at = NOW();
    
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER attendance_financial_trigger
    AFTER INSERT OR UPDATE ON attendance_records
    FOR EACH ROW EXECUTE FUNCTION calculate_daily_financials();
```

### 1.2 RESTful API Development

#### 1.2.1 Enhanced API Architecture
```typescript
// Advanced API structure with comprehensive endpoints
interface APIEndpoints {
  // Employee Management
  'GET /api/v1/employees': {
    query: EmployeeFilters;
    response: PaginatedResponse<Employee>;
  };
  'POST /api/v1/employees': {
    body: CreateEmployeeRequest;
    response: Employee;
  };
  'PUT /api/v1/employees/:id': {
    params: { id: string };
    body: UpdateEmployeeRequest;
    response: Employee;
  };
  'DELETE /api/v1/employees/:id': {
    params: { id: string };
    response: DeleteResponse;
  };
  'GET /api/v1/employees/:id/performance': {
    params: { id: string };
    query: { startDate?: string; endDate?: string };
    response: PerformanceMetrics;
  };
  'GET /api/v1/employees/:id/documents': {
    params: { id: string };
    response: EmployeeDocument[];
  };
  'POST /api/v1/employees/:id/documents': {
    params: { id: string };
    body: FormData;
    response: EmployeeDocument;
  };

  // Project Management
  'GET /api/v1/projects': {
    query: ProjectFilters;
    response: PaginatedResponse<Project>;
  };
  'POST /api/v1/projects': {
    body: CreateProjectRequest;
    response: Project;
  };
  'PUT /api/v1/projects/:id/status': {
    params: { id: string };
    body: UpdateProjectStatusRequest;
    response: Project;
  };
  'GET /api/v1/projects/:id/financials': {
    params: { id: string };
    query: { startDate?: string; endDate?: string };
    response: ProjectFinancials;
  };

  // Attendance Management
  'GET /api/v1/attendance': {
    query: AttendanceFilters;
    response: PaginatedResponse<AttendanceRecord>;
  };
  'POST /api/v1/attendance': {
    body: CreateAttendanceRequest;
    response: AttendanceRecord;
  };
  'POST /api/v1/attendance/bulk': {
    body: BulkAttendanceRequest;
    response: BulkAttendanceResponse;
  };
  'GET /api/v1/attendance/reports/daily': {
    query: DailyReportQuery;
    response: DailyAttendanceReport;
  };
  'GET /api/v1/attendance/reports/period': {
    query: PeriodReportQuery;
    response: PeriodAttendanceReport;
  };

  // Financial Intelligence
  'GET /api/v1/financials/dashboard': {
    query: DashboardFilters;
    response: DashboardMetrics;
  };
  'GET /api/v1/financials/profit-trends': {
    query: TrendFilters;
    response: ProfitTrendData[];
  };
  'GET /api/v1/financials/insights': {
    query: InsightFilters;
    response: ActionableInsight[];
  };
  'POST /api/v1/financials/calculate': {
    body: CalculationRequest;
    response: FinancialCalculation;
  };

  // Invoice Management
  'GET /api/v1/invoices': {
    query: InvoiceFilters;
    response: PaginatedResponse<Invoice>;
  };
  'POST /api/v1/invoices': {
    body: CreateInvoiceRequest;
    response: Invoice;
  };
  'PUT /api/v1/invoices/:id/status': {
    params: { id: string };
    body: UpdateInvoiceStatusRequest;
    response: Invoice;
  };
  'POST /api/v1/invoices/:id/send': {
    params: { id: string };
    body: SendInvoiceRequest;
    response: SendInvoiceResponse;
  };
  'GET /api/v1/invoices/:id/pdf': {
    params: { id: string };
    response: Buffer;
  };

  // Document Management
  'POST /api/v1/documents/upload': {
    body: FormData;
    response: DocumentUploadResponse;
  };
  'GET /api/v1/documents/:id/download': {
    params: { id: string };
    response: Buffer;
  };
  'GET /api/v1/documents/expiring': {
    query: { days?: number };
    response: ExpiringDocument[];
  };

  // Reporting & Analytics
  'GET /api/v1/reports/workforce-analytics': {
    query: AnalyticsFilters;
    response: WorkforceAnalytics;
  };
  'POST /api/v1/reports/generate': {
    body: ReportGenerationRequest;
    response: ReportGenerationResponse;
  };
  'GET /api/v1/reports/:id/download': {
    params: { id: string };
    response: Buffer;
  };

  // System Administration
  'GET /api/v1/admin/system-health': {
    response: SystemHealthMetrics;
  };
  'GET /api/v1/admin/audit-logs': {
    query: AuditLogFilters;
    response: PaginatedResponse<AuditLog>;
  };
  'POST /api/v1/admin/backup': {
    response: BackupResponse;
  };
}
```

#### 1.2.2 Advanced API Implementation
```typescript
// Enhanced Express.js server with comprehensive middleware
import express from 'express';
import cors from 'cors';
import helmet from 'helmet';
import rateLimit from 'express-rate-limit';
import compression from 'compression';
import { Pool } from 'pg';
import jwt from 'jsonwebtoken';
import bcrypt from 'bcrypt';
import multer from 'multer';
import sharp from 'sharp';
import { z } from 'zod';

const app = express();

// Enhanced security middleware
app.use(helmet({
  contentSecurityPolicy: {
    directives: {
      defaultSrc: ["'self'"],
      styleSrc: ["'self'", "'unsafe-inline'"],
      scriptSrc: ["'self'"],
      imgSrc: ["'self'", "data:", "https:"],
    },
  },
  hsts: {
    maxAge: 31536000,
    includeSubDomains: true,
    preload: true
  }
}));

// Rate limiting
const limiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 100, // limit each IP to 100 requests per windowMs
  message: 'Too many requests from this IP',
  standardHeaders: true,
  legacyHeaders: false,
});
app.use('/api/', limiter);

// Enhanced CORS configuration
app.use(cors({
  origin: process.env.ALLOWED_ORIGINS?.split(',') || ['http://localhost:5173'],
  credentials: true,
  methods: ['GET', 'POST', 'PUT', 'DELETE', 'PATCH'],
  allowedHeaders: ['Content-Type', 'Authorization', 'X-Requested-With']
}));

app.use(compression());
app.use(express.json({ limit: '10mb' }));
app.use(express.urlencoded({ extended: true, limit: '10mb' }));

// Database connection with connection pooling
const pool = new Pool({
  host: process.env.DB_HOST,
  port: parseInt(process.env.DB_PORT || '5432'),
  database: process.env.DB_NAME,
  user: process.env.DB_USER,
  password: process.env.DB_PASSWORD,
  ssl: process.env.NODE_ENV === 'production' ? { rejectUnauthorized: false } : false,
  max: 20, // maximum number of clients in the pool
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 2000,
});

// Enhanced authentication middleware
interface AuthenticatedRequest extends express.Request {
  user?: {
    id: string;
    email: string;
    role: string;
    permissions: string[];
  };
}

const authenticateToken = async (req: AuthenticatedRequest, res: express.Response, next: express.NextFunction) => {
  const authHeader = req.headers['authorization'];
  const token = authHeader && authHeader.split(' ')[1];

  if (!token) {
    return res.status(401).json({ error: 'Access token required' });
  }

  try {
    const decoded = jwt.verify(token, process.env.JWT_SECRET!) as any;
    
    // Verify user still exists and is active
    const userResult = await pool.query(
      'SELECT id, email, role, is_active FROM users WHERE id = $1 AND is_active = true',
      [decoded.userId]
    );

    if (userResult.rows.length === 0) {
      return res.status(401).json({ error: 'Invalid or expired token' });
    }

    const user = userResult.rows[0];
    
    // Get user permissions
    const permissionsResult = await pool.query(`
      SELECT p.permission_name 
      FROM user_permissions up
      JOIN permissions p ON up.permission_id = p.id
      WHERE up.user_id = $1
    `, [user.id]);

    req.user = {
      id: user.id,
      email: user.email,
      role: user.role,
      permissions: permissionsResult.rows.map(row => row.permission_name)
    };

    // Set user context for audit logging
    await pool.query("SELECT set_config('app.current_user_id', $1, true)", [user.id]);

    next();
  } catch (error) {
    return res.status(403).json({ error: 'Invalid token' });
  }
};

// Permission-based authorization middleware
const requirePermission = (permission: string) => {
  return (req: AuthenticatedRequest, res: express.Response, next: express.NextFunction) => {
    if (!req.user?.permissions.includes(permission) && !req.user?.permissions.includes('admin:all')) {
      return res.status(403).json({ error: 'Insufficient permissions' });
    }
    next();
  };
};

// Enhanced validation middleware using Zod
const validateRequest = (schema: z.ZodSchema) => {
  return (req: express.Request, res: express.Response, next: express.NextFunction) => {
    try {
      schema.parse({
        body: req.body,
        query: req.query,
        params: req.params
      });
      next();
    } catch (error) {
      if (error instanceof z.ZodError) {
        return res.status(400).json({
          error: 'Validation failed',
          details: error.errors
        });
      }
      next(error);
    }
  };
};

// Employee management endpoints with enhanced features
const employeeSchema = z.object({
  body: z.object({
    name: z.string().min(2).max(255),
    nameAr: z.string().optional(),
    trade: z.string().min(2).max(100),
    nationality: z.string().min(2).max(100),
    phoneNumber: z.string().regex(/^\+966[0-9]{9}$/),
    email: z.string().email().optional(),
    hourlyRate: z.number().min(18).max(500),
    actualRate: z.number().min(20).max(1000),
    projectId: z.string().uuid().optional(),
    skills: z.array(z.string()).default([]),
    certifications: z.array(z.string()).default([])
  })
});

app.post('/api/v1/employees', 
  authenticateToken,
  requirePermission('employees:create'),
  validateRequest(employeeSchema),
  async (req: AuthenticatedRequest, res: express.Response) => {
    const client = await pool.connect();
    
    try {
      await client.query('BEGIN');
      
      // Check for duplicate employee ID
      const duplicateCheck = await client.query(
        'SELECT id FROM employees WHERE employee_id = $1',
        [req.body.employeeId]
      );
      
      if (duplicateCheck.rows.length > 0) {
        await client.query('ROLLBACK');
        return res.status(409).json({ error: 'Employee ID already exists' });
      }

      // Generate employee ID if not provided
      const employeeId = req.body.employeeId || await generateEmployeeId(client);

      const result = await client.query(`
        INSERT INTO employees (
          employee_id, name, name_ar, trade, nationality, phone_number, email,
          hourly_rate, actual_rate, project_id, skills, certifications, created_by
        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13)
        RETURNING *
      `, [
        employeeId, req.body.name, req.body.nameAr, req.body.trade,
        req.body.nationality, req.body.phoneNumber, req.body.email,
        req.body.hourlyRate, req.body.actualRate, req.body.projectId,
        JSON.stringify(req.body.skills), JSON.stringify(req.body.certifications),
        req.user!.id
      ]);

      await client.query('COMMIT');
      
      res.status(201).json({
        success: true,
        data: result.rows[0],
        message: 'Employee created successfully'
      });
    } catch (error) {
      await client.query('ROLLBACK');
      console.error('Error creating employee:', error);
      res.status(500).json({ error: 'Internal server error' });
    } finally {
      client.release();
    }
  }
);

// Advanced search and filtering
app.get('/api/v1/employees',
  authenticateToken,
  requirePermission('employees:read'),
  async (req: AuthenticatedRequest, res: express.Response) => {
    try {
      const {
        page = 1,
        limit = 50,
        search,
        nationality,
        trade,
        project,
        status,
        sortBy = 'name',
        sortOrder = 'ASC'
      } = req.query;

      let whereConditions = ['1=1'];
      let queryParams: any[] = [];
      let paramIndex = 1;

      // Full-text search
      if (search) {
        whereConditions.push(`to_tsvector('english', name || ' ' || trade || ' ' || nationality) @@ plainto_tsquery('english', $${paramIndex})`);
        queryParams.push(search);
        paramIndex++;
      }

      // Filter conditions
      if (nationality) {
        whereConditions.push(`nationality = $${paramIndex}`);
        queryParams.push(nationality);
        paramIndex++;
      }

      if (trade) {
        whereConditions.push(`trade = $${paramIndex}`);
        queryParams.push(trade);
        paramIndex++;
      }

      if (project) {
        whereConditions.push(`project_id = $${paramIndex}`);
        queryParams.push(project);
        paramIndex++;
      }

      if (status) {
        whereConditions.push(`status = $${paramIndex}`);
        queryParams.push(status);
        paramIndex++;
      }

      const offset = (Number(page) - 1) * Number(limit);
      
      // Get total count
      const countResult = await pool.query(`
        SELECT COUNT(*) as total
        FROM employees e
        LEFT JOIN projects p ON e.project_id = p.id
        WHERE ${whereConditions.join(' AND ')}
      `, queryParams);

      // Get paginated results with project information
      const dataResult = await pool.query(`
        SELECT 
          e.*,
          p.name as project_name,
          p.client as project_client,
          (
            SELECT COUNT(*)
            FROM employee_documents ed
            WHERE ed.employee_id = e.id 
            AND ed.expiry_date IS NOT NULL 
            AND ed.expiry_date <= CURRENT_DATE + INTERVAL '30 days'
          ) as expiring_documents_count
        FROM employees e
        LEFT JOIN projects p ON e.project_id = p.id
        WHERE ${whereConditions.join(' AND ')}
        ORDER BY ${sortBy} ${sortOrder}
        LIMIT $${paramIndex} OFFSET $${paramIndex + 1}
      `, [...queryParams, limit, offset]);

      const total = parseInt(countResult.rows[0].total);
      const totalPages = Math.ceil(total / Number(limit));

      res.json({
        success: true,
        data: dataResult.rows,
        pagination: {
          page: Number(page),
          limit: Number(limit),
          total,
          totalPages,
          hasNext: Number(page) < totalPages,
          hasPrev: Number(page) > 1
        }
      });
    } catch (error) {
      console.error('Error fetching employees:', error);
      res.status(500).json({ error: 'Internal server error' });
    }
  }
);
```

### 1.3 Authentication & Authorization

#### 1.3.1 Advanced Authentication System
```typescript
// Multi-factor authentication implementation
interface AuthenticationService {
  // Primary authentication
  login(credentials: LoginCredentials): Promise<AuthResponse>;
  
  // Multi-factor authentication
  enableMFA(userId: string): Promise<MFASetupResponse>;
  verifyMFA(userId: string, token: string): Promise<MFAVerificationResponse>;
  
  // Session management
  refreshToken(refreshToken: string): Promise<TokenResponse>;
  logout(userId: string, sessionId: string): Promise<void>;
  logoutAllSessions(userId: string): Promise<void>;
  
  // Password management
  changePassword(userId: string, oldPassword: string, newPassword: string): Promise<void>;
  resetPassword(email: string): Promise<PasswordResetResponse>;
  
  // Account security
  lockAccount(userId: string, reason: string): Promise<void>;
  unlockAccount(userId: string): Promise<void>;
  getLoginHistory(userId: string): Promise<LoginHistory[]>;
}

// JWT token service with enhanced security
class TokenService {
  private readonly accessTokenExpiry = '15m';
  private readonly refreshTokenExpiry = '7d';
  private readonly jwtSecret = process.env.JWT_SECRET!;
  private readonly refreshSecret = process.env.JWT_REFRESH_SECRET!;

  generateTokens(user: User): TokenPair {
    const payload = {
      userId: user.id,
      email: user.email,
      role: user.role,
      permissions: user.permissions,
      sessionId: uuid.v4()
    };

    const accessToken = jwt.sign(payload, this.jwtSecret, {
      expiresIn: this.accessTokenExpiry,
      issuer: 'HRMS-workforce',
      audience: 'HRMS-users'
    });

    const refreshToken = jwt.sign(
      { userId: user.id, sessionId: payload.sessionId },
      this.refreshSecret,
      { expiresIn: this.refreshTokenExpiry }
    );

    return { accessToken, refreshToken, expiresIn: 900 }; // 15 minutes
  }

  async verifyAccessToken(token: string): Promise<TokenPayload> {
    try {
      const decoded = jwt.verify(token, this.jwtSecret, {
        issuer: 'HRMS-workforce',
        audience: 'HRMS-users'
      }) as TokenPayload;

      // Check if session is still valid
      const sessionValid = await this.isSessionValid(decoded.userId, decoded.sessionId);
      if (!sessionValid) {
        throw new Error('Session expired');
      }

      return decoded;
    } catch (error) {
      throw new Error('Invalid or expired token');
    }
  }

  private async isSessionValid(userId: string, sessionId: string): Promise<boolean> {
    const result = await pool.query(
      'SELECT id FROM user_sessions WHERE user_id = $1 AND session_id = $2 AND expires_at > NOW()',
      [userId, sessionId]
    );
    return result.rows.length > 0;
  }
}

// Role-based access control (RBAC)
class AuthorizationService {
  private permissions = new Map<string, Permission[]>();

  async loadPermissions(): Promise<void> {
    const result = await pool.query(`
      SELECT r.name as role_name, p.permission_name, p.resource, p.action
      FROM roles r
      JOIN role_permissions rp ON r.id = rp.role_id
      JOIN permissions p ON rp.permission_id = p.id
      WHERE r.is_active = true
    `);

    result.rows.forEach(row => {
      if (!this.permissions.has(row.role_name)) {
        this.permissions.set(row.role_name, []);
      }
      this.permissions.get(row.role_name)!.push({
        name: row.permission_name,
        resource: row.resource,
        action: row.action
      });
    });
  }

  hasPermission(userRole: string, resource: string, action: string): boolean {
    const rolePermissions = this.permissions.get(userRole) || [];
    return rolePermissions.some(p => 
      (p.resource === resource || p.resource === '*') &&
      (p.action === action || p.action === '*')
    );
  }

  async checkResourceAccess(userId: string, resourceId: string, resourceType: string): Promise<boolean> {
    // Check if user has access to specific resource (e.g., project, employee)
    const result = await pool.query(`
      SELECT 1 FROM resource_access 
      WHERE user_id = $1 AND resource_id = $2 AND resource_type = $3
      UNION
      SELECT 1 FROM users WHERE id = $1 AND role = 'admin'
    `, [userId, resourceId, resourceType]);

    return result.rows.length > 0;
  }
}
```

### 1.4 Data Migration Strategy

#### 1.4.1 Advanced Migration Service
```typescript
// Comprehensive data migration from localStorage to PostgreSQL
class DataMigrationService {
  private readonly batchSize = 100;
  private readonly validationRules = new Map<string, ValidationRule[]>();

  async migrateAllData(): Promise<MigrationResult> {
    const migrationResult: MigrationResult = {
      employees: { total: 0, migrated: 0, failed: 0, errors: [] },
      projects: { total: 0, migrated: 0, failed: 0, errors: [] },
      attendance: { total: 0, migrated: 0, failed: 0, errors: [] },
      documents: { total: 0, migrated: 0, failed: 0, errors: [] },
      startTime: new Date(),
      endTime: null,
      status: 'in-progress'
    };

    try {
      // Migrate in dependency order
      await this.migrateProjects(migrationResult);
      await this.migrateEmployees(migrationResult);
      await this.migrateAttendance(migrationResult);
      await this.migrateDocuments(migrationResult);

      migrationResult.status = 'completed';
      migrationResult.endTime = new Date();

      // Generate migration report
      await this.generateMigrationReport(migrationResult);

      return migrationResult;
    } catch (error) {
      migrationResult.status = 'failed';
      migrationResult.endTime = new Date();
      throw error;
    }
  }

  private async migrateEmployees(result: MigrationResult): Promise<void> {
    const localStorageData = this.getLocalStorageData('workforce_employees');
    if (!localStorageData) return;

    const employees = JSON.parse(localStorageData);
    result.employees.total = employees.length;

    // Process in batches
    for (let i = 0; i < employees.length; i += this.batchSize) {
      const batch = employees.slice(i, i + this.batchSize);
      
      for (const employee of batch) {
        try {
          // Validate employee data
          const validationResult = this.validateEmployeeData(employee);
          if (!validationResult.valid) {
            result.employees.failed++;
            result.employees.errors.push({
              id: employee.id,
              errors: validationResult.errors
            });
            continue;
          }

          // Transform and insert
          const transformedEmployee = this.transformEmployeeData(employee);
          await this.insertEmployee(transformedEmployee);
          
          result.employees.migrated++;
        } catch (error) {
          result.employees.failed++;
          result.employees.errors.push({
            id: employee.id,
            error: error.message
          });
        }
      }
    }
  }

  private validateEmployeeData(employee: any): ValidationResult {
    const errors: string[] = [];

    // Required fields validation
    if (!employee.name || employee.name.trim().length < 2) {
      errors.push('Employee name is required and must be at least 2 characters');
    }

    if (!employee.employeeId || !/^EMP\d{3,}$/.test(employee.employeeId)) {
      errors.push('Employee ID must follow format EMP### (e.g., EMP001)');
    }

    if (!employee.phoneNumber || !/^\+966[0-9]{9}$/.test(employee.phoneNumber)) {
      errors.push('Phone number must be valid Saudi format (+966XXXXXXXXX)');
    }

    if (employee.hourlyRate < 18.00) {
      errors.push('Hourly rate cannot be below Saudi minimum wage (18.00 SAR)');
    }

    if (employee.actualRate <= employee.hourlyRate) {
      errors.push('Actual rate must be higher than hourly rate for profitability');
    }

    // Business logic validation
    if (employee.actualRate > employee.hourlyRate * 5) {
      errors.push('Actual rate seems unusually high compared to hourly rate - please verify');
    }

    return {
      valid: errors.length === 0,
      errors
    };
  }

  private transformEmployeeData(employee: any): TransformedEmployee {
    return {
      employeeId: employee.employeeId,
      name: employee.name,
      nameAr: employee.nameAr || null,
      trade: employee.trade,
      nationality: employee.nationality,
      phoneNumber: employee.phoneNumber,
      email: employee.email || null,
      hourlyRate: parseFloat(employee.hourlyRate),
      actualRate: parseFloat(employee.actualRate),
      projectId: employee.projectId || null,
      status: employee.status || 'active',
      skills: Array.isArray(employee.skills) ? employee.skills : [],
      certifications: Array.isArray(employee.certifications) ? employee.certifications : [],
      performanceRating: employee.performanceRating || 85,
      emergencyContact: employee.emergencyContact ? JSON.stringify(employee.emergencyContact) : null,
      metadata: {
        migratedFrom: 'localStorage',
        originalId: employee.id,
        migrationDate: new Date().toISOString()
      }
    };
  }

  private async insertEmployee(employee: TransformedEmployee): Promise<void> {
    await pool.query(`
      INSERT INTO employees (
        employee_id, name, name_ar, trade, nationality, phone_number, email,
        hourly_rate, actual_rate, project_id, status, skills, certifications,
        performance_rating, emergency_contact, metadata, created_by
      ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17)
    `, [
      employee.employeeId, employee.name, employee.nameAr, employee.trade,
      employee.nationality, employee.phoneNumber, employee.email,
      employee.hourlyRate, employee.actualRate, employee.projectId,
      employee.status, JSON.stringify(employee.skills), JSON.stringify(employee.certifications),
      employee.performanceRating, employee.emergencyContact, JSON.stringify(employee.metadata),
      'migration-system' // Special system user for migration
    ]);
  }

  private getLocalStorageData(key: string): string | null {
    // In a real migration, this would read from exported localStorage data
    // For now, we'll simulate reading from a JSON file
    try {
      const fs = require('fs');
      const path = require('path');
      const dataPath = path.join(__dirname, 'migration-data', `${key}.json`);
      return fs.readFileSync(dataPath, 'utf8');
    } catch (error) {
      console.warn(`No migration data found for ${key}`);
      return null;
    }
  }
}
```

---

## Phase 2: Real-time Features (Weeks 5-8)
**Budget: $35,000 | Team: 3 developers | Priority: HIGH**

### 2.1 WebSocket Implementation for Live Updates

#### 2.1.1 Advanced WebSocket Architecture
```typescript
// Comprehensive WebSocket server with room-based subscriptions
import { Server as SocketIOServer } from 'socket.io';
import { createAdapter } from '@socket.io/redis-adapter';
import Redis from 'ioredis';

interface WebSocketEvents {
  // Dashboard updates
  'dashboard:metrics': DashboardMetrics;
  'dashboard:subscribe': { projectId?: string; departmentId?: string };
  'dashboard:unsubscribe': { projectId?: string; departmentId?: string };

  // Attendance updates
  'attendance:new': AttendanceRecord;
  'attendance:updated': AttendanceRecord;
  'attendance:bulk-update': AttendanceRecord[];

  // Project updates
  'project:status-changed': ProjectStatusUpdate;
  'project:progress-updated': ProjectProgressUpdate;
  'project:team-assigned': TeamAssignmentUpdate;

  // Employee updates
  'employee:created': Employee;
  'employee:updated': Employee;
  'employee:status-changed': EmployeeStatusUpdate;

  // Financial updates
  'financials:profit-update': ProfitUpdate;
  'financials:insight-generated': ActionableInsight;

  // Notifications
  'notification:new': Notification;
  'notification:read': { notificationId: string };

  // Collaboration
  'user:joined': { userId: string; userName: string; room: string };
  'user:left': { userId: string; room: string };
  'cursor:moved': { userId: string; position: CursorPosition };
}

class EnhancedWebSocketService {
  private io: SocketIOServer;
  private redis: Redis;
  private connectedUsers = new Map<string, UserConnection>();

  constructor(server: any) {
    this.redis = new Redis(process.env.REDIS_URL);
    
    this.io = new SocketIOServer(server, {
      cors: {
        origin: process.env.ALLOWED_ORIGINS?.split(',') || ['http://localhost:5173'],
        credentials: true
      },
      adapter: createAdapter(this.redis, this.redis.duplicate())
    });

    this.setupMiddleware();
    this.setupEventHandlers();
  }

  private setupMiddleware(): void {
    // Authentication middleware
    this.io.use(async (socket, next) => {
      try {
        const token = socket.handshake.auth.token;
        const decoded = jwt.verify(token, process.env.JWT_SECRET!) as any;
        
        const userResult = await pool.query(
          'SELECT id, email, role, name FROM users WHERE id = $1 AND is_active = true',
          [decoded.userId]
        );

        if (userResult.rows.length === 0) {
          throw new Error('User not found');
        }

        socket.data.user = userResult.rows[0];
        next();
      } catch (error) {
        next(new Error('Authentication failed'));
      }
    });

    // Rate limiting middleware
    this.io.use(async (socket, next) => {
      const userId = socket.data.user.id;
      const key = `ws_rate_limit:${userId}`;
      
      const current = await this.redis.incr(key);
      if (current === 1) {
        await this.redis.expire(key, 60); // 1 minute window
      }
      
      if (current > 100) { // 100 events per minute
        next(new Error('Rate limit exceeded'));
        return;
      }
      
      next();
    });
  }

  private setupEventHandlers(): void {
    this.io.on('connection', (socket) => {
      const user = socket.data.user;
      
      // Store user connection
      this.connectedUsers.set(socket.id, {
        userId: user.id,
        userName: user.name,
        email: user.email,
        role: user.role,
        connectedAt: new Date(),
        lastActivity: new Date()
      });

      console.log(`User ${user.name} connected (${socket.id})`);

      // Dashboard subscription
      socket.on('dashboard:subscribe', async (data) => {
        const room = this.getDashboardRoom(data.projectId, data.departmentId);
        await socket.join(room);
        
        // Send initial dashboard data
        const metrics = await this.getDashboardMetrics(data.projectId, data.departmentId);
        socket.emit('dashboard:metrics', metrics);
      });

      // Project room subscription
      socket.on('project:subscribe', async (projectId: string) => {
        await socket.join(`project:${projectId}`);
        
        // Send initial project data
        const projectData = await this.getProjectData(projectId);
        socket.emit('project:data', projectData);
      });

      // Real-time collaboration
      socket.on('cursor:move', (data) => {
        socket.to(data.room).emit('cursor:moved', {
          userId: user.id,
          userName: user.name,
          position: data.position
        });
      });

      // Attendance updates
      socket.on('attendance:submit', async (attendanceData) => {
        try {
          const attendance = await this.processAttendance(attendanceData, user.id);
          
          // Broadcast to relevant rooms
          this.io.to(`project:${attendance.projectId}`).emit('attendance:new', attendance);
          this.io.to('dashboard:all').emit('dashboard:metrics', await this.getDashboardMetrics());
          
          socket.emit('attendance:submitted', { success: true, data: attendance });
        } catch (error) {
          socket.emit('attendance:error', { error: error.message });
        }
      });

      // Disconnect handling
      socket.on('disconnect', () => {
        this.connectedUsers.delete(socket.id);
        console.log(`User ${user.name} disconnected`);
      });

      // Update last activity
      socket.onAny(() => {
        const connection = this.connectedUsers.get(socket.id);
        if (connection) {
          connection.lastActivity = new Date();
        }
      });
    });
  }

  // Real-time dashboard metrics calculation
  private async getDashboardMetrics(projectId?: string, departmentId?: string): Promise<DashboardMetrics> {
    const whereConditions = ['1=1'];
    const params: any[] = [];
    let paramIndex = 1;

    if (projectId) {
      whereConditions.push(`e.project_id = $${paramIndex}`);
      params.push(projectId);
      paramIndex++;
    }

    if (departmentId) {
      whereConditions.push(`e.department_id = $${paramIndex}`);
      params.push(departmentId);
      paramIndex++;
    }

    const result = await pool.query(`
      SELECT 
        COUNT(DISTINCT e.id) as total_workforce,
        COUNT(DISTINCT CASE WHEN e.status = 'active' THEN e.id END) as active_workforce,
        COUNT(DISTINCT p.id) as active_projects,
        COALESCE(SUM(fc.labor_cost), 0) as total_costs,
        COALESCE(SUM(fc.revenue), 0) as total_revenue,
        COALESCE(SUM(fc.profit), 0) as total_profits,
        COALESCE(AVG(fc.profit_margin), 0) as avg_profit_margin,
        COALESCE(SUM(fc.regular_hours + fc.overtime_hours), 0) as total_hours
      FROM employees e
      LEFT JOIN projects p ON e.project_id = p.id AND p.status = 'active'
      LEFT JOIN financial_calculations fc ON e.id = fc.employee_id 
        AND fc.calculation_date >= CURRENT_DATE - INTERVAL '30 days'
      WHERE ${whereConditions.join(' AND ')}
    `, params);

    const metrics = result.rows[0];
    
    return {
      totalWorkforce: parseInt(metrics.total_workforce),
      activeWorkforce: parseInt(metrics.active_workforce),
      activeProjects: parseInt(metrics.active_projects),
      aggregateHours: parseFloat(metrics.total_hours),
      crossProjectRevenue: parseFloat(metrics.total_revenue),
      realTimeProfits: parseFloat(metrics.total_profits),
      averageProfitMargin: parseFloat(metrics.avg_profit_margin),
      utilizationRate: metrics.total_workforce > 0 ? 
        (metrics.active_workforce / metrics.total_workforce) * 100 : 0,
      productivityIndex: metrics.total_hours > 0 ? 
        metrics.total_revenue / metrics.total_hours : 0,
      lastUpdated: new Date()
    };
  }

  // Broadcast updates to relevant subscribers
  async broadcastUpdate(updateType: string, data: any, targetRooms?: string[]): Promise<void> {
    if (targetRooms) {
      targetRooms.forEach(room => {
        this.io.to(room).emit(updateType, data);
      });
    } else {
      this.io.emit(updateType, data);
    }

    // Cache update for new connections
    await this.redis.setex(`last_update:${updateType}`, 300, JSON.stringify(data));
  }
}
```

### 2.2 Real-time Dashboard Metrics

#### 2.2.1 Live Metrics Engine
```typescript
// Advanced real-time metrics calculation engine
class LiveMetricsEngine {
  private metricsCache = new Map<string, CachedMetric>();
  private updateQueue = new Queue<MetricUpdate>();
  private isProcessing = false;

  async startMetricsEngine(): Promise<void> {
    // Process metrics updates every 5 seconds
    setInterval(() => this.processMetricsQueue(), 5000);
    
    // Refresh cached metrics every minute
    setInterval(() => this.refreshCachedMetrics(), 60000);
    
    // Clean up old metrics every hour
    setInterval(() => this.cleanupOldMetrics(), 3600000);
  }

  async calculateLiveMetrics(filters: MetricFilters): Promise<LiveDashboardMetrics> {
    const cacheKey = this.generateCacheKey(filters);
    const cached = this.metricsCache.get(cacheKey);
    
    if (cached && this.isCacheValid(cached)) {
      return cached.data;
    }

    const metrics = await this.computeMetrics(filters);
    
    // Cache the results
    this.metricsCache.set(cacheKey, {
      data: metrics,
      computedAt: new Date(),
      expiresAt: new Date(Date.now() + 30000) // 30 seconds cache
    });

    return metrics;
  }

  private async computeMetrics(filters: MetricFilters): Promise<LiveDashboardMetrics> {
    const startTime = performance.now();

    // Parallel execution of metric calculations
    const [
      workforceMetrics,
      financialMetrics,
      projectMetrics,
      attendanceMetrics,
      performanceMetrics
    ] = await Promise.all([
      this.calculateWorkforceMetrics(filters),
      this.calculateFinancialMetrics(filters),
      this.calculateProjectMetrics(filters),
      this.calculateAttendanceMetrics(filters),
      this.calculatePerformanceMetrics(filters)
    ]);

    const computationTime = performance.now() - startTime;

    return {
      ...workforceMetrics,
      ...financialMetrics,
      ...projectMetrics,
      ...attendanceMetrics,
      ...performanceMetrics,
      metadata: {
        computedAt: new Date(),
        computationTimeMs: computationTime,
        cacheKey: this.generateCacheKey(filters),
        dataFreshness: 'live'
      }
    };
  }

  private async calculateWorkforceMetrics(filters: MetricFilters): Promise<WorkforceMetrics> {
    const result = await pool.query(`
      WITH workforce_stats AS (
        SELECT 
          COUNT(*) as total_employees,
          COUNT(CASE WHEN status = 'active' THEN 1 END) as active_employees,
          COUNT(CASE WHEN project_id IS NOT NULL THEN 1 END) as assigned_employees,
          COUNT(CASE WHEN created_at >= CURRENT_DATE - INTERVAL '30 days' THEN 1 END) as new_hires
        FROM employees
        WHERE ($1::UUID IS NULL OR project_id = $1)
        AND ($2::VARCHAR IS NULL OR nationality = $2)
        AND ($3::VARCHAR IS NULL OR trade = $3)
      )
      SELECT 
        *,
        CASE WHEN total_employees > 0 
          THEN (assigned_employees::DECIMAL / total_employees) * 100 
          ELSE 0 
        END as utilization_rate
      FROM workforce_stats
    `, [filters.projectId, filters.nationality, filters.trade]);

    const stats = result.rows[0];

    return {
      totalWorkforce: parseInt(stats.total_employees),
      activeWorkforce: parseInt(stats.active_employees),
      assignedWorkforce: parseInt(stats.assigned_employees),
      newHires: parseInt(stats.new_hires),
      utilizationRate: parseFloat(stats.utilization_rate)
    };
  }

  private async calculateFinancialMetrics(filters: MetricFilters): Promise<FinancialMetrics> {
    const result = await pool.query(`
      SELECT 
        COALESCE(SUM(labor_cost), 0) as total_costs,
        COALESCE(SUM(revenue), 0) as total_revenue,
        COALESCE(SUM(profit), 0) as total_profits,
        COALESCE(AVG(profit_margin), 0) as avg_profit_margin,
        COALESCE(SUM(regular_hours + overtime_hours), 0) as total_hours,
        COUNT(DISTINCT employee_id) as contributing_employees
      FROM financial_calculations fc
      JOIN employees e ON fc.employee_id = e.id
      WHERE fc.calculation_date >= CURRENT_DATE - INTERVAL '30 days'
      AND ($1::UUID IS NULL OR fc.project_id = $1)
      AND ($2::VARCHAR IS NULL OR e.nationality = $2)
      AND ($3::VARCHAR IS NULL OR e.trade = $3)
    `, [filters.projectId, filters.nationality, filters.trade]);

    const stats = result.rows[0];

    return {
      totalCosts: parseFloat(stats.total_costs),
      totalRevenue: parseFloat(stats.total_revenue),
      totalProfits: parseFloat(stats.total_profits),
      averageProfitMargin: parseFloat(stats.avg_profit_margin),
      totalHours: parseFloat(stats.total_hours),
      productivityIndex: stats.total_hours > 0 ? 
        stats.total_revenue / stats.total_hours : 0,
      contributingEmployees: parseInt(stats.contributing_employees)
    };
  }
}
```

### 2.3 Collaborative Features

#### 2.3.1 Real-time Collaboration System
```typescript
// Advanced collaboration features for team coordination
interface CollaborationFeatures {
  // Real-time document editing
  documentCollaboration: DocumentCollaborationService;
  
  // Live project status updates
  projectCollaboration: ProjectCollaborationService;
  
  // Team communication
  teamChat: TeamChatService;
  
  // Shared workspaces
  sharedWorkspaces: WorkspaceService;
}

class DocumentCollaborationService {
  private activeDocuments = new Map<string, DocumentSession>();

  async joinDocumentSession(documentId: string, userId: string): Promise<DocumentSession> {
    let session = this.activeDocuments.get(documentId);
    
    if (!session) {
      session = {
        documentId,
        participants: new Map(),
        changes: [],
        lastSaved: new Date(),
        version: 1
      };
      this.activeDocuments.set(documentId, session);
    }

    session.participants.set(userId, {
      userId,
      joinedAt: new Date(),
      cursor: { line: 0, column: 0 },
      isActive: true
    });

    return session;
  }

  async applyDocumentChange(documentId: string, change: DocumentChange): Promise<void> {
    const session = this.activeDocuments.get(documentId);
    if (!session) throw new Error('Document session not found');

    // Apply operational transformation
    const transformedChange = this.transformChange(change, session.changes);
    session.changes.push(transformedChange);

    // Broadcast to all participants
    session.participants.forEach((participant, userId) => {
      if (userId !== change.userId) {
        this.broadcastToUser(userId, 'document:change', transformedChange);
      }
    });

    // Auto-save every 30 seconds
    if (Date.now() - session.lastSaved.getTime() > 30000) {
      await this.saveDocument(documentId, session);
    }
  }

  private transformChange(change: DocumentChange, existingChanges: DocumentChange[]): DocumentChange {
    // Implement operational transformation algorithm
    // This ensures consistency when multiple users edit simultaneously
    let transformedChange = { ...change };
    
    for (const existingChange of existingChanges) {
      if (existingChange.timestamp > change.timestamp) {
        transformedChange = this.transformAgainst(transformedChange, existingChange);
      }
    }
    
    return transformedChange;
  }
}

class ProjectCollaborationService {
  async updateProjectStatus(
    projectId: string, 
    statusUpdate: ProjectStatusUpdate, 
    userId: string
  ): Promise<void> {
    const client = await pool.connect();
    
    try {
      await client.query('BEGIN');
      
      // Update project status
      await client.query(`
        UPDATE projects 
        SET status = $1, progress = $2, updated_at = NOW()
        WHERE id = $3
      `, [statusUpdate.status, statusUpdate.progress, projectId]);
      
      // Create status history entry
      await client.query(`
        INSERT INTO project_status_history (
          project_id, previous_status, new_status, progress, 
          changed_by, change_reason, notes
        ) VALUES ($1, $2, $3, $4, $5, $6, $7)
      `, [
        projectId, statusUpdate.previousStatus, statusUpdate.status,
        statusUpdate.progress, userId, statusUpdate.reason, statusUpdate.notes
      ]);

      await client.query('COMMIT');

      // Broadcast update to all project subscribers
      this.broadcastProjectUpdate(projectId, {
        type: 'status-changed',
        projectId,
        status: statusUpdate.status,
        progress: statusUpdate.progress,
        changedBy: userId,
        timestamp: new Date()
      });

      // Trigger follow-up workflow if required
      if (statusUpdate.requiresFollowUp) {
        await this.scheduleFollowUp(projectId, statusUpdate.followUp!);
      }

    } catch (error) {
      await client.query('ROLLBACK');
      throw error;
    } finally {
      client.release();
    }
  }

  private async scheduleFollowUp(projectId: string, followUp: FollowUpRequest): Promise<void> {
    await pool.query(`
      INSERT INTO project_follow_ups (
        project_id, follow_up_date, follow_up_time, action_description,
        priority, assigned_to, reminder_preference
      ) VALUES ($1, $2, $3, $4, $5, $6, $7)
    `, [
      projectId, followUp.date, followUp.time, followUp.description,
      followUp.priority, followUp.assignedTo, followUp.reminderPreference
    ]);

    // Schedule notification
    await this.scheduleNotification(followUp);
  }
}
```

---

## Phase 3: Mobile & AI (Weeks 9-12)
**Budget: $60,000 | Team: 4 developers | Priority: HIGH**

### 3.1 React Native Mobile Application

#### 3.1.1 Advanced Mobile Architecture
```typescript
// Comprehensive React Native app with offline capabilities
import React from 'react';
import { NavigationContainer } from '@react-navigation/native';
import { createBottomTabNavigator } from '@react-navigation/bottom-tabs';
import { createStackNavigator } from '@react-navigation/stack';
import AsyncStorage from '@react-native-async-storage/async-storage';
import NetInfo from '@react-native-community/netinfo';
import { Camera } from 'expo-camera';
import * as Location from 'expo-location';
import * as Notifications from 'expo-notifications';
import { Provider } from 'react-redux';
import { PersistGate } from 'redux-persist/integration/react';

// Enhanced mobile app structure
interface MobileAppFeatures {
  // Core features
  authentication: AuthenticationScreen;
  dashboard: MobileDashboard;
  attendance: AttendanceModule;
  projects: ProjectModule;
  
  // Field worker features
  clockInOut: ClockInOutModule;
  photoProgress: PhotoProgressModule;
  gpsTracking: GPSTrackingModule;
  offlineSync: OfflineSyncModule;
  
  // Supervisor features
  teamManagement: TeamManagementModule;
  approvals: ApprovalsModule;
  reporting: MobileReportingModule;
  
  // Communication
  notifications: NotificationModule;
  messaging: MessagingModule;
  emergencyContact: EmergencyModule;
}

// Offline-first architecture
class OfflineDataManager {
  private syncQueue: SyncOperation[] = [];
  private isOnline = true;
  private lastSyncTime: Date | null = null;

  constructor() {
    this.setupNetworkListener();
    this.setupPeriodicSync();
  }

  private setupNetworkListener(): void {
    NetInfo.addEventListener(state => {
      const wasOffline = !this.isOnline;
      this.isOnline = state.isConnected || false;
      
      if (wasOffline && this.isOnline) {
        // Back online - start sync
        this.syncPendingOperations();
      }
    });
  }

  async saveOfflineData(operation: OfflineOperation): Promise<void> {
    // Save to local storage
    const offlineData = await AsyncStorage.getItem('offline_operations') || '[]';
    const operations = JSON.parse(offlineData);
    
    operations.push({
      ...operation,
      id: uuid.v4(),
      timestamp: new Date().toISOString(),
      status: 'pending'
    });

    await AsyncStorage.setItem('offline_operations', JSON.stringify(operations));
    
    // Add to sync queue
    this.syncQueue.push(operation);
    
    // Try immediate sync if online
    if (this.isOnline) {
      this.syncPendingOperations();
    }
  }

  private async syncPendingOperations(): Promise<void> {
    if (this.syncQueue.length === 0) return;

    const operations = [...this.syncQueue];
    this.syncQueue = [];

    for (const operation of operations) {
      try {
        await this.syncOperation(operation);
        await this.markOperationSynced(operation.id);
      } catch (error) {
        // Re-queue failed operations
        this.syncQueue.push(operation);
        console.error('Sync failed for operation:', operation.id, error);
      }
    }

    this.lastSyncTime = new Date();
  }

  private async syncOperation(operation: OfflineOperation): Promise<void> {
    switch (operation.type) {
      case 'attendance':
        await this.syncAttendance(operation.data);
        break;
      case 'photo_upload':
        await this.syncPhotoUpload(operation.data);
        break;
      case 'status_update':
        await this.syncStatusUpdate(operation.data);
        break;
      default:
        throw new Error(`Unknown operation type: ${operation.type}`);
    }
  }
}

// Enhanced attendance module with biometric and GPS
class MobileAttendanceModule extends React.Component {
  state = {
    isClockingIn: false,
    currentLocation: null,
    biometricAvailable: false,
    cameraPermission: false
  };

  async componentDidMount() {
    await this.requestPermissions();
    await this.checkBiometricAvailability();
  }

  private async requestPermissions(): Promise<void> {
    // Location permission
    const { status: locationStatus } = await Location.requestForegroundPermissionsAsync();
    
    // Camera permission
    const { status: cameraStatus } = await Camera.requestCameraPermissionsAsync();
    
    // Notification permission
    const { status: notificationStatus } = await Notifications.requestPermissionsAsync();

    this.setState({
      locationPermission: locationStatus === 'granted',
      cameraPermission: cameraStatus === 'granted',
      notificationPermission: notificationStatus === 'granted'
    });
  }

  async handleClockIn(): Promise<void> {
    this.setState({ isClockingIn: true });

    try {
      // Get current location
      const location = await Location.getCurrentPositionAsync({
        accuracy: Location.Accuracy.High
      });

      // Verify work location (geofencing)
      const isAtWorkLocation = await this.verifyWorkLocation(location.coords);
      if (!isAtWorkLocation) {
        throw new Error('You must be at the work location to clock in');
      }

      // Biometric verification (if available)
      let biometricVerified = false;
      if (this.state.biometricAvailable) {
        biometricVerified = await this.performBiometricVerification();
      }

      // Take verification photo
      const photoUri = await this.takeVerificationPhoto();

      // Create attendance record
      const attendanceData = {
        employeeId: await this.getCurrentEmployeeId(),
        clockInTime: new Date().toISOString(),
        location: {
          latitude: location.coords.latitude,
          longitude: location.coords.longitude,
          accuracy: location.coords.accuracy
        },
        biometricVerified,
        photoVerificationUri: photoUri,
        deviceInfo: await this.getDeviceInfo()
      };

      // Save locally first (offline-first approach)
      await this.offlineDataManager.saveOfflineData({
        type: 'attendance',
        data: attendanceData
      });

      // Show success message
      this.showSuccessMessage('Clocked in successfully');

      // Send push notification to supervisor
      await this.notifySupervisor('clock_in', attendanceData);

    } catch (error) {
      this.showErrorMessage(error.message);
    } finally {
      this.setState({ isClockingIn: false });
    }
  }

  private async verifyWorkLocation(coords: LocationCoords): Promise<boolean> {
    const workLocations = await this.getWorkLocations();
    
    return workLocations.some(workLocation => {
      const distance = this.calculateDistance(coords, workLocation.coordinates);
      return distance <= workLocation.radius; // Within allowed radius
    });
  }

  private async takeVerificationPhoto(): Promise<string> {
    // Implement photo capture with face detection
    const photo = await this.camera.takePictureAsync({
      quality: 0.8,
      base64: false,
      exif: true
    });

    // Compress and optimize photo
    const compressedPhoto = await this.compressPhoto(photo.uri);
    
    // Store locally and queue for upload
    const localUri = await this.storePhotoLocally(compressedPhoto);
    
    return localUri;
  }
}

// Advanced photo progress tracking
class PhotoProgressModule extends React.Component {
  async captureWorkProgress(projectId: string, taskId: string): Promise<void> {
    try {
      // Get current location
      const location = await Location.getCurrentPositionAsync();
      
      // Take multiple photos (before, during, after)
      const photos = await this.captureMultiplePhotos();
      
      // Add metadata to photos
      const enhancedPhotos = await Promise.all(
        photos.map(async (photo, index) => ({
          ...photo,
          metadata: {
            projectId,
            taskId,
            sequenceNumber: index + 1,
            timestamp: new Date().toISOString(),
            location: {
              latitude: location.coords.latitude,
              longitude: location.coords.longitude
            },
            weather: await this.getWeatherData(location.coords),
            deviceInfo: await this.getDeviceInfo()
          }
        }))
      );

      // AI-powered photo analysis
      const analysisResults = await this.analyzePhotos(enhancedPhotos);
      
      // Create progress report
      const progressReport = {
        projectId,
        taskId,
        photos: enhancedPhotos,
        analysis: analysisResults,
        submittedBy: await this.getCurrentUserId(),
        submittedAt: new Date().toISOString(),
        gpsVerified: true,
        qualityScore: analysisResults.averageQuality
      };

      // Save offline first
      await this.offlineDataManager.saveOfflineData({
        type: 'photo_progress',
        data: progressReport
      });

      this.showSuccessMessage('Progress photos captured and queued for upload');

    } catch (error) {
      this.showErrorMessage(`Failed to capture progress: ${error.message}`);
    }
  }

  private async analyzePhotos(photos: EnhancedPhoto[]): Promise<PhotoAnalysisResult> {
    // AI-powered photo analysis
    const analysisPromises = photos.map(async (photo) => {
      const analysis = await this.aiPhotoAnalyzer.analyze(photo);
      return {
        photoId: photo.id,
        qualityScore: analysis.quality,
        duplicateDetection: analysis.isDuplicate,
        safetyCompliance: analysis.safetyCheck,
        workProgress: analysis.progressAssessment,
        anomalies: analysis.detectedAnomalies
      };
    });

    const results = await Promise.all(analysisPromises);
    
    return {
      totalPhotos: photos.length,
      averageQuality: results.reduce((sum, r) => sum + r.qualityScore, 0) / results.length,
      duplicatesDetected: results.filter(r => r.duplicateDetection).length,
      safetyIssues: results.filter(r => !r.safetyCompliance).length,
      overallScore: this.calculateOverallScore(results),
      recommendations: this.generateRecommendations(results)
    };
  }
}
```

### 3.2 AI-Powered Insights and Recommendations

#### 3.2.1 Advanced AI Analytics Engine
```typescript
// Comprehensive AI-powered insights system
interface AIInsightsEngine {
  // Predictive analytics
  predictiveAnalytics: PredictiveAnalyticsService;
  
  // Optimization recommendations
  optimizationEngine: OptimizationEngine;
  
  // Anomaly detection
  anomalyDetection: AnomalyDetectionService;
  
  // Natural language insights
  nlpInsights: NLPInsightsService;
}

class PredictiveAnalyticsService {
  private models = new Map<string, MLModel>();

  async initializeModels(): Promise<void> {
    // Load pre-trained models
    this.models.set('profit_prediction', await this.loadModel('profit_prediction'));
    this.models.set('attendance_forecast', await this.loadModel('attendance_forecast'));
    this.models.set('project_risk', await this.loadModel('project_risk'));
    this.models.set('employee_performance', await this.loadModel('employee_performance'));
  }

  async predictProfitTrends(projectId: string, timeframe: number): Promise<ProfitPrediction> {
    const model = this.models.get('profit_prediction');
    if (!model) throw new Error('Profit prediction model not loaded');

    // Gather historical data
    const historicalData = await this.getHistoricalProfitData(projectId, 90); // 90 days
    
    // Prepare features
    const features = this.prepareProfitFeatures(historicalData);
    
    // Make prediction
    const prediction = await model.predict(features);
    
    return {
      projectId,
      timeframe,
      predictedProfit: prediction.profit,
      confidence: prediction.confidence,
      factors: prediction.influencingFactors,
      recommendations: await this.generateProfitRecommendations(prediction),
      generatedAt: new Date()
    };
  }

  async forecastAttendance(projectId: string, days: number): Promise<AttendanceForecast> {
    const model = this.models.get('attendance_forecast');
    if (!model) throw new Error('Attendance forecast model not loaded');

    // Get historical attendance patterns
    const historicalAttendance = await this.getHistoricalAttendanceData(projectId, 60);
    
    // Consider external factors
    const externalFactors = await this.getExternalFactors(days);
    
    // Prepare features
    const features = this.prepareAttendanceFeatures(historicalAttendance, externalFactors);
    
    // Generate forecast
    const forecast = await model.predict(features);
    
    return {
      projectId,
      forecastPeriod: days,
      dailyForecasts: forecast.dailyPredictions,
      expectedAttendanceRate: forecast.averageAttendance,
      riskFactors: forecast.identifiedRisks,
      recommendations: await this.generateAttendanceRecommendations(forecast),
      confidence: forecast.confidence
    };
  }

  async assessProjectRisk(projectId: string): Promise<ProjectRiskAssessment> {
    const model = this.models.get('project_risk');
    if (!model) throw new Error('Project risk model not loaded');

    // Gather comprehensive project data
    const projectData = await this.getComprehensiveProjectData(projectId);
    
    // Prepare risk features
    const features = this.prepareRiskFeatures(projectData);
    
    // Assess risk
    const riskAssessment = await model.predict(features);
    
    return {
      projectId,
      overallRiskScore: riskAssessment.riskScore,
      riskLevel: this.categorizeRiskLevel(riskAssessment.riskScore),
      riskFactors: riskAssessment.identifiedFactors,
      mitigationStrategies: await this.generateMitigationStrategies(riskAssessment),
      probabilityOfDelay: riskAssessment.delayProbability,
      budgetRiskAssessment: riskAssessment.budgetRisk,
      recommendedActions: riskAssessment.recommendedActions,
      assessmentDate: new Date()
    };
  }

  private async generateProfitRecommendations(prediction: ProfitPrediction): Promise<Recommendation[]> {
    const recommendations: Recommendation[] = [];

    // Analyze profit trends
    if (prediction.profit < 0) {
      recommendations.push({
        type: 'critical',
        title: 'Negative Profit Projection',
        description: 'Project is predicted to operate at a loss',
        actions: [
          'Review and optimize hourly rates',
          'Reduce overtime dependency',
          'Improve operational efficiency',
          'Renegotiate contract terms if possible'
        ],
        expectedImpact: 'High',
        implementationCost: 'Medium',
        timeframe: 'Immediate'
      });
    }

    // Rate optimization recommendations
    if (prediction.factors.includes('low_margin')) {
      recommendations.push({
        type: 'optimization',
        title: 'Rate Optimization Opportunity',
        description: 'Profit margins could be improved through rate adjustments',
        actions: [
          'Increase actual rates by 10-15%',
          'Implement performance-based bonuses',
          'Optimize resource allocation'
        ],
        expectedImpact: 'Medium',
        implementationCost: 'Low',
        timeframe: 'Short-term'
      });
    }

    return recommendations;
  }
}

class OptimizationEngine {
  async optimizeResourceAllocation(constraints: OptimizationConstraints): Promise<OptimizationResult> {
    // Advanced optimization using linear programming
    const optimizer = new LinearProgrammingSolver();
    
    // Define objective function (maximize profit)
    const objectiveFunction = this.buildProfitObjectiveFunction(constraints);
    
    // Define constraints
    const constraintSet = this.buildConstraintSet(constraints);
    
    // Solve optimization problem
    const solution = await optimizer.solve(objectiveFunction, constraintSet);
    
    return {
      optimalAllocation: solution.allocation,
      expectedProfit: solution.objectiveValue,
      improvementPercentage: solution.improvementOverCurrent,
      recommendations: this.generateAllocationRecommendations(solution),
      implementationPlan: this.createImplementationPlan(solution)
    };
  }

  private buildProfitObjectiveFunction(constraints: OptimizationConstraints): ObjectiveFunction {
    // Maximize: (actual_rate - hourly_rate) * hours_allocated
    return {
      type: 'maximize',
      variables: constraints.employees.map(emp => ({
        id: emp.id,
        coefficient: emp.actualRate - emp.hourlyRate
      }))
    };
  }

  private buildConstraintSet(constraints: OptimizationConstraints): Constraint[] {
    const constraintSet: Constraint[] = [];

    // Project requirements constraints
    constraints.projects.forEach(project => {
      constraintSet.push({
        type: 'equality',
        description: `Project ${project.name} workforce requirement`,
        variables: project.requiredSkills.map(skill => ({
          employeeIds: constraints.employees
            .filter(emp => emp.skills.includes(skill))
            .map(emp => emp.id),
          coefficient: 1
        })),
        value: project.requiredWorkers
      });
    });

    // Employee availability constraints
    constraints.employees.forEach(employee => {
      constraintSet.push({
        type: 'less_than_equal',
        description: `Employee ${employee.name} availability`,
        variables: [{ id: employee.id, coefficient: 1 }],
        value: employee.maxHoursPerWeek
      });
    });

    // Budget constraints
    constraintSet.push({
      type: 'less_than_equal',
      description: 'Total budget constraint',
      variables: constraints.employees.map(emp => ({
        id: emp.id,
        coefficient: emp.hourlyRate
      })),
      value: constraints.totalBudget
    });

    return constraintSet;
  }
}
```

### 3.3 Predictive Analytics

#### 3.3.1 Advanced Machine Learning Pipeline
```typescript
// Comprehensive ML pipeline for workforce analytics
class MachineLearningPipeline {
  private dataProcessor: DataProcessor;
  private featureEngineering: FeatureEngineeringService;
  private modelTrainer: ModelTrainingService;
  private predictionService: PredictionService;

  async trainProfitPredictionModel(): Promise<ModelTrainingResult> {
    // Data collection and preprocessing
    const rawData = await this.collectTrainingData('profit_prediction', 365); // 1 year of data
    const cleanedData = await this.dataProcessor.clean(rawData);
    
    // Feature engineering
    const features = await this.featureEngineering.createProfitFeatures(cleanedData);
    
    // Model training with cross-validation
    const trainingResult = await this.modelTrainer.trainModel({
      algorithm: 'gradient_boosting',
      features,
      target: 'profit_margin',
      hyperparameters: {
        n_estimators: 100,
        learning_rate: 0.1,
        max_depth: 6,
        subsample: 0.8
      },
      validation: {
        method: 'time_series_split',
        n_splits: 5
      }
    });

    // Model evaluation
    const evaluation = await this.evaluateModel(trainingResult.model, features);
    
    // Deploy model if performance is acceptable
    if (evaluation.accuracy > 0.85) {
      await this.deployModel('profit_prediction', trainingResult.model);
    }

    return {
      modelId: trainingResult.modelId,
      accuracy: evaluation.accuracy,
      precision: evaluation.precision,
      recall: evaluation.recall,
      f1Score: evaluation.f1Score,
      featureImportance: evaluation.featureImportance,
      deploymentStatus: evaluation.accuracy > 0.85 ? 'deployed' : 'pending_review'
    };
  }

  async generatePredictiveInsights(): Promise<PredictiveInsight[]> {
    const insights: PredictiveInsight[] = [];

    // Profit trend predictions
    const profitPredictions = await this.predictProfitTrends();
    insights.push(...this.convertProfitPredictionsToInsights(profitPredictions));

    // Employee performance predictions
    const performancePredictions = await this.predictEmployeePerformance();
    insights.push(...this.convertPerformancePredictionsToInsights(performancePredictions));

    // Project completion predictions
    const completionPredictions = await this.predictProjectCompletion();
    insights.push(...this.convertCompletionPredictionsToInsights(completionPredictions));

    // Resource optimization opportunities
    const optimizationOpportunities = await this.identifyOptimizationOpportunities();
    insights.push(...optimizationOpportunities);

    return insights.sort((a, b) => b.priority - a.priority);
  }

  private async predictProfitTrends(): Promise<ProfitTrendPrediction[]> {
    const projects = await this.getActiveProjects();
    const predictions: ProfitTrendPrediction[] = [];

    for (const project of projects) {
      const historicalData = await this.getProjectHistoricalData(project.id, 90);
      const features = this.featureEngineering.createTimeSeriesFeatures(historicalData);
      
      const model = await this.getModel('profit_prediction');
      const prediction = await model.predict(features);
      
      predictions.push({
        projectId: project.id,
        projectName: project.name,
        currentProfitMargin: project.currentProfitMargin,
        predictedProfitMargin: prediction.profitMargin,
        trendDirection: prediction.trend,
        confidence: prediction.confidence,
        timeframe: 30, // 30 days
        factors: prediction.influencingFactors
      });
    }

    return predictions;
  }
}

// Natural Language Processing for insights
class NLPInsightsService {
  async generateNaturalLanguageInsights(data: AnalyticsData): Promise<NLInsight[]> {
    const insights: NLInsight[] = [];

    // Analyze workforce trends
    const workforceTrend = this.analyzeWorkforceTrend(data.workforce);
    insights.push({
      category: 'workforce',
      insight: this.generateWorkforceInsight(workforceTrend),
      confidence: workforceTrend.confidence,
      actionable: true,
      recommendations: workforceTrend.recommendations
    });

    // Analyze financial performance
    const financialTrend = this.analyzeFinancialTrend(data.financial);
    insights.push({
      category: 'financial',
      insight: this.generateFinancialInsight(financialTrend),
      confidence: financialTrend.confidence,
      actionable: true,
      recommendations: financialTrend.recommendations
    });

    // Analyze project performance
    const projectTrends = this.analyzeProjectTrends(data.projects);
    insights.push(...projectTrends.map(trend => ({
      category: 'project',
      insight: this.generateProjectInsight(trend),
      confidence: trend.confidence,
      actionable: true,
      recommendations: trend.recommendations
    })));

    return insights;
  }

  private generateWorkforceInsight(trend: WorkforceTrend): string {
    const templates = {
      positive: [
        "Your workforce utilization has improved by {percentage}% over the last {period}, indicating excellent resource management.",
        "Employee productivity is trending upward with a {percentage}% increase in output per hour.",
        "The team is performing exceptionally well with {metric} showing consistent improvement."
      ],
      negative: [
        "Workforce utilization has declined by {percentage}% in the past {period}, suggesting potential optimization opportunities.",
        "Employee productivity metrics indicate a {percentage}% decrease that requires attention.",
        "There are signs of workforce inefficiency with {metric} showing concerning trends."
      ],
      neutral: [
        "Workforce metrics remain stable with {metric} maintaining consistent levels over {period}.",
        "Your team performance is steady, with opportunities for strategic improvements in {area}."
      ]
    };

    const template = this.selectTemplate(templates[trend.direction], trend.significance);
    return this.populateTemplate(template, trend.data);
  }

  private generateFinancialInsight(trend: FinancialTrend): string {
    if (trend.profitMargin > 25) {
      return `Excellent financial performance with ${trend.profitMargin.toFixed(1)}% profit margin. Your current rate structure is highly effective, generating ${this.formatCurrency(trend.monthlyProfit)} in monthly profits.`;
    } else if (trend.profitMargin < 15) {
      return `Profit margins at ${trend.profitMargin.toFixed(1)}% are below optimal levels. Consider reviewing actual rates and optimizing cost structure to improve profitability by an estimated ${this.formatCurrency(trend.improvementPotential)}.`;
    } else {
      return `Profit margins at ${trend.profitMargin.toFixed(1)}% are within acceptable range. There's potential to optimize further through strategic rate adjustments and efficiency improvements.`;
    }
  }
}
```

---

## Phase 4: Production Readiness (Weeks 13-16)
**Budget: $30,000 | Team: 4 developers + 1 DevOps | Priority: CRITICAL**

### 4.1 Comprehensive Testing Implementation

#### 4.1.1 Advanced Testing Strategy
```typescript
// Comprehensive testing framework with multiple testing layers
interface TestingFramework {
  unitTesting: UnitTestSuite;
  integrationTesting: IntegrationTestSuite;
  e2eTesting: E2ETestSuite;
  performanceTesting: PerformanceTestSuite;
  securityTesting: SecurityTestSuite;
  accessibilityTesting: AccessibilityTestSuite;
}

// Enhanced unit testing with comprehensive coverage
describe('Financial Calculations Engine', () => {
  describe('Profit Margin Calculations', () => {
    test('should calculate correct profit margin for standard hours', () => {
      const result = calculateFinancials(8, 0, 25.00, 40.00);
      expect(result.profit).toBe(120.00); // (8 * 40) - (8 * 25)
      expect(result.profitMargin).toBeCloseTo(37.5, 1); // (120/320) * 100
    });

    test('should handle overtime calculations correctly', () => {
      const result = calculateFinancials(8, 2, 25.00, 40.00);
      expect(result.laborCost).toBe(275.00); // (8*25) + (2*25*1.5)
      expect(result.revenue).toBe(440.00); // (8*40) + (2*40*1.5)
      expect(result.profit).toBe(165.00);
      expect(result.profitMargin).toBeCloseTo(37.5, 1);
    });

    test('should validate minimum wage compliance', () => {
      expect(() => calculateFinancials(8, 0, 15.00, 30.00))
        .toThrow('Hourly rate below Saudi minimum wage');
    });

    test('should handle edge cases gracefully', () => {
      expect(calculateFinancials(0, 0, 25.00, 40.00).profit).toBe(0);
      expect(calculateFinancials(8, 0, 40.00, 40.00).profitMargin).toBe(0);
    });
  });

  describe('Employee Performance Metrics', () => {
    test('should calculate attendance rate correctly', () => {
      const attendanceRecords = createMockAttendanceRecords(20, 22); // 20 present out of 22 days
      const performance = calculateEmployeePerformance(mockEmployee, attendanceRecords);
      expect(performance.attendanceRate).toBeCloseTo(90.9, 1);
    });

    test('should calculate efficiency metrics', () => {
      const attendanceRecords = createMockAttendanceRecords(20, 22, 8.5); // 8.5 avg hours
      const performance = calculateEmployeePerformance(mockEmployee, attendanceRecords);
      expect(performance.efficiency).toBeCloseTo(106.25, 1); // (8.5/8) * 100
    });
  });
});

// Integration testing with database
describe('Employee API Integration', () => {
  let testDb: TestDatabase;
  let apiClient: APIClient;

  beforeAll(async () => {
    testDb = await setupTestDatabase();
    apiClient = new APIClient(TEST_API_URL);
  });

  afterAll(async () => {
    await testDb.cleanup();
  });

  beforeEach(async () => {
    await testDb.reset();
    await seedTestData(testDb);
  });

  test('should create employee with complete validation', async () => {
    const employeeData = createValidEmployeeData();
    const response = await apiClient.post('/api/v1/employees', employeeData);
    
    expect(response.status).toBe(201);
    expect(response.data.success).toBe(true);
    expect(response.data.data.id).toBeDefined();
    
    // Verify database insertion
    const dbEmployee = await testDb.query('SELECT * FROM employees WHERE id = $1', [response.data.data.id]);
    expect(dbEmployee.rows).toHaveLength(1);
    expect(dbEmployee.rows[0].name).toBe(employeeData.name);
  });

  test('should handle duplicate employee ID gracefully', async () => {
    const employeeData = createValidEmployeeData();
    await apiClient.post('/api/v1/employees', employeeData);
    
    const response = await apiClient.post('/api/v1/employees', employeeData);
    expect(response.status).toBe(409);
    expect(response.data.error).toContain('Employee ID already exists');
  });

  test('should validate Saudi labor law compliance', async () => {
    const invalidEmployeeData = createValidEmployeeData();
    invalidEmployeeData.hourlyRate = 15.00; // Below minimum wage
    
    const response = await apiClient.post('/api/v1/employees', invalidEmployeeData);
    expect(response.status).toBe(400);
    expect(response.data.error).toContain('minimum wage');
  });
});

// End-to-end testing with Playwright
describe('E2E Workforce Management Workflows', () => {
  test('complete employee lifecycle workflow', async ({ page }) => {
    // Login
    await page.goto('/login');
    await page.fill('[data-testid=email]', 'hr@HRMS.sa');
    await page.fill('[data-testid=password]', 'test123');
    await page.click('[data-testid=login-button]');
    
    // Navigate to employee management
    await page.click('[data-testid=sidebar-manpower]');
    await expect(page.locator('h1')).toContainText('Manpower');
    
    // Add new employee
    await page.click('[data-testid=add-employee-button]');
    await page.fill('[data-testid=employee-name]', 'Test Employee');
    await page.fill('[data-testid=employee-id]', 'EMP999');
    await page.selectOption('[data-testid=trade]', 'Electrician');
    await page.selectOption('[data-testid=nationality]', 'Saudi');
    await page.fill('[data-testid=phone]', '+966501234567');
    await page.fill('[data-testid=hourly-rate]', '30.00');
    await page.fill('[data-testid=actual-rate]', '45.00');
    
    await page.click('[data-testid=save-employee]');
    
    // Verify employee appears in list
    await expect(page.locator('[data-testid=employee-list]')).toContainText('Test Employee');
    
    // Record attendance
    await page.click('[data-testid=attendance-tab]');
    await page.selectOption('[data-testid=employee-select]', 'EMP999');
    await page.fill('[data-testid=hours-worked]', '8');
    await page.fill('[data-testid=overtime]', '2');
    await page.click('[data-testid=save-attendance]');
    
    // Verify financial calculations
    await expect(page.locator('[data-testid=daily-profit]')).toContainText('135.00'); // Expected profit
    
    // Generate report
    await page.click('[data-testid=generate-report]');
    await expect(page.locator('[data-testid=report-content]')).toBeVisible();
  });

  test('project management workflow', async ({ page }) => {
    await loginAsProjectManager(page);
    
    // Create new project
    await page.click('[data-testid=add-project]');
    await fillProjectForm(page, {
      name: 'Test Project',
      client: 'Test Client',
      budget: 500000,
      startDate: '2024-01-01',
      endDate: '2024-12-31'
    });
    
    // Assign employees
    await page.click('[data-testid=assign-employees]');
    await page.check('[data-testid=employee-EMP001]');
    await page.check('[data-testid=employee-EMP002]');
    await page.click('[data-testid=confirm-assignment]');
    
    // Update project status
    await page.click('[data-testid=update-status]');
    await page.selectOption('[data-testid=status-select]', 'active');
    await page.fill('[data-testid=progress]', '25');
    await page.fill('[data-testid=status-notes]', 'Project kickoff completed');
    await page.click('[data-testid=save-status]');
    
    // Verify dashboard updates
    await page.click('[data-testid=dashboard-link]');
    await expect(page.locator('[data-testid=active-projects]')).toContainText('1');
  });
});

// Performance testing with comprehensive load scenarios
describe('Performance Testing Suite', () => {
  test('dashboard metrics calculation under load', async () => {
    const startTime = performance.now();
    
    // Simulate 1000 concurrent users requesting dashboard metrics
    const promises = Array.from({ length: 1000 }, () => 
      apiClient.get('/api/v1/financials/dashboard')
    );
    
    const responses = await Promise.all(promises);
    const endTime = performance.now();
    
    // Verify all requests succeeded
    responses.forEach(response => {
      expect(response.status).toBe(200);
      expect(response.data.success).toBe(true);
    });
    
    // Verify performance requirements
    const totalTime = endTime - startTime;
    const avgResponseTime = totalTime / 1000;
    expect(avgResponseTime).toBeLessThan(500); // < 500ms average
  });

  test('database query performance with large datasets', async () => {
    // Seed database with 10,000 employees and 100,000 attendance records
    await seedLargeDataset(testDb, 10000, 100000);
    
    const startTime = performance.now();
    
    // Complex query with joins and aggregations
    const result = await testDb.query(`
      SELECT 
        e.name, e.trade, p.name as project_name,
        SUM(fc.hours_worked) as total_hours,
        SUM(fc.profit) as total_profit,
        AVG(fc.profit_margin) as avg_margin
      FROM employees e
      JOIN financial_calculations fc ON e.id = fc.employee_id
      LEFT JOIN projects p ON e.project_id = p.id
      WHERE fc.calculation_date >= CURRENT_DATE - INTERVAL '90 days'
      GROUP BY e.id, e.name, e.trade, p.name
      ORDER BY total_profit DESC
      LIMIT 100
    `);
    
    const queryTime = performance.now() - startTime;
    
    expect(result.rows).toHaveLength(100);
    expect(queryTime).toBeLessThan(100); // < 100ms for complex query
  });
});
```

### 4.2 Security Hardening

#### 4.2.1 Advanced Security Implementation
```typescript
// Comprehensive security framework
interface SecurityFramework {
  authentication: EnhancedAuthenticationService;
  authorization: RoleBasedAccessControl;
  dataProtection: DataProtectionService;
  auditLogging: AuditLoggingService;
  threatDetection: ThreatDetectionService;
  compliance: ComplianceService;
}

class EnhancedSecurityService {
  private encryptionService: EncryptionService;
  private auditLogger: AuditLogger;
  private threatDetector: ThreatDetector;

  constructor() {
    this.encryptionService = new EncryptionService();
    this.auditLogger = new AuditLogger();
    this.threatDetector = new ThreatDetector();
  }

  // Advanced input sanitization and validation
  sanitizeAndValidate(input: any, schema: ValidationSchema): SanitizedData {
    // Remove potentially dangerous characters
    const sanitized = this.sanitizeInput(input);
    
    // Validate against schema
    const validation = this.validateInput(sanitized, schema);
    if (!validation.valid) {
      throw new ValidationError(validation.errors);
    }
    
    // Additional security checks
    this.performSecurityChecks(sanitized);
    
    return sanitized;
  }

  private sanitizeInput(input: any): any {
    if (typeof input === 'string') {
      return input
        .replace(/<script\b[^<]*(?:(?!<\/script>)<[^<]*)*<\/script>/gi, '') // Remove script tags
        .replace(/javascript:/gi, '') // Remove javascript: protocols
        .replace(/on\w+\s*=/gi, '') // Remove event handlers
        .trim();
    }
    
    if (Array.isArray(input)) {
      return input.map(item => this.sanitizeInput(item));
    }
    
    if (typeof input === 'object' && input !== null) {
      const sanitized: any = {};
      for (const [key, value] of Object.entries(input)) {
        sanitized[this.sanitizeInput(key)] = this.sanitizeInput(value);
      }
      return sanitized;
    }
    
    return input;
  }

  // SQL injection prevention
  private validateSQLQuery(query: string, params: any[]): void {
    // Check for SQL injection patterns
    const dangerousPatterns = [
      /(\b(SELECT|INSERT|UPDATE|DELETE|DROP|CREATE|ALTER|EXEC|UNION)\b)/i,
      /(--|\/\*|\*\/)/,
      /(\b(OR|AND)\b.*=.*)/i
    ];

    const hasInjection = dangerousPatterns.some(pattern => pattern.test(query));
    if (hasInjection && !this.isWhitelistedQuery(query)) {
      throw new SecurityError('Potential SQL injection detected');
    }

    // Validate parameter count
    const paramCount = (query.match(/\$\d+/g) || []).length;
    if (paramCount !== params.length) {
      throw new SecurityError('Parameter count mismatch');
    }
  }

  // Advanced threat detection
  async detectThreats(request: SecurityRequest): Promise<ThreatAssessment> {
    const threats: DetectedThreat[] = [];

    // Rate limiting check
    const rateLimitThreat = await this.checkRateLimit(request);
    if (rateLimitThreat) threats.push(rateLimitThreat);

    // Suspicious pattern detection
    const patternThreat = await this.detectSuspiciousPatterns(request);
    if (patternThreat) threats.push(patternThreat);

    // Geolocation anomaly detection
    const geoThreat = await this.detectGeolocationAnomalies(request);
    if (geoThreat) threats.push(geoThreat);

    // Device fingerprinting
    const deviceThreat = await this.detectDeviceAnomalies(request);
    if (deviceThreat) threats.push(deviceThreat);

    return {
      riskLevel: this.calculateRiskLevel(threats),
      threats,
      recommendedActions: this.generateSecurityActions(threats),
      shouldBlock: threats.some(t => t.severity === 'critical')
    };
  }

  // Data encryption at rest and in transit
  async encryptSensitiveData(data: SensitiveData): Promise<EncryptedData> {
    const encryptionKey = await this.getEncryptionKey(data.classification);
    
    return {
      encryptedData: await this.encryptionService.encrypt(data.content, encryptionKey),
      keyId: encryptionKey.id,
      algorithm: 'AES-256-GCM',
      encryptedAt: new Date(),
      classification: data.classification
    };
  }

  // Comprehensive audit logging
  async logSecurityEvent(event: SecurityEvent): Promise<void> {
    const auditEntry = {
      eventType: event.type,
      userId: event.userId,
      ipAddress: event.ipAddress,
      userAgent: event.userAgent,
      resource: event.resource,
      action: event.action,
      result: event.result,
      riskLevel: event.riskLevel,
      metadata: event.metadata,
      timestamp: new Date()
    };

    await this.auditLogger.log(auditEntry);

    // Real-time threat monitoring
    if (event.riskLevel === 'high' || event.riskLevel === 'critical') {
      await this.alertSecurityTeam(auditEntry);
    }
  }
}

// Compliance monitoring service
class ComplianceService {
  async validateSaudiLaborLawCompliance(operation: ComplianceOperation): Promise<ComplianceResult> {
    const violations: ComplianceViolation[] = [];

    switch (operation.type) {
      case 'employee_creation':
        violations.push(...await this.validateEmployeeCompliance(operation.data));
        break;
      case 'attendance_record':
        violations.push(...await this.validateAttendanceCompliance(operation.data));
        break;
      case 'payroll_calculation':
        violations.push(...await this.validatePayrollCompliance(operation.data));
        break;
    }

    return {
      isCompliant: violations.length === 0,
      violations,
      recommendations: this.generateComplianceRecommendations(violations),
      auditTrail: await this.createComplianceAuditTrail(operation)
    };
  }

  private async validateEmployeeCompliance(employeeData: any): Promise<ComplianceViolation[]> {
    const violations: ComplianceViolation[] = [];

    // Minimum wage compliance
    if (employeeData.hourlyRate < 18.00) {
      violations.push({
        type: 'minimum_wage_violation',
        severity: 'critical',
        description: 'Hourly rate below Saudi minimum wage (18.00 SAR)',
        legalReference: 'Saudi Labor Law Article 95',
        remediation: 'Adjust hourly rate to meet minimum wage requirements'
      });
    }

    // Working hours compliance
    if (employeeData.maxWeeklyHours > 48) {
      violations.push({
        type: 'working_hours_violation',
        severity: 'high',
        description: 'Maximum weekly hours exceed legal limit (48 hours)',
        legalReference: 'Saudi Labor Law Article 98',
        remediation: 'Reduce maximum weekly hours to 48 or obtain special permit'
      });
    }

    // Document requirements
    const requiredDocuments = ['iqama', 'contract', 'medical-report'];
    const missingDocuments = requiredDocuments.filter(doc => 
      !employeeData.documents?.some((d: any) => d.type === doc)
    );

    if (missingDocuments.length > 0) {
      violations.push({
        type: 'documentation_violation',
        severity: 'medium',
        description: `Missing required documents: ${missingDocuments.join(', ')}`,
        legalReference: 'Saudi Labor Law Article 37',
        remediation: 'Obtain and upload missing documentation'
      });
    }

    return violations;
  }
}
```

### 4.3 Performance Optimization

#### 4.3.1 Advanced Performance Optimization
```typescript
// Comprehensive performance optimization framework
interface PerformanceOptimization {
  databaseOptimization: DatabaseOptimizationService;
  caching: CachingService;
  loadBalancing: LoadBalancingService;
  assetOptimization: AssetOptimizationService;
  monitoring: PerformanceMonitoringService;
}

class DatabaseOptimizationService {
  async optimizeQueries(): Promise<OptimizationResult> {
    const optimizations: QueryOptimization[] = [];

    // Analyze slow queries
    const slowQueries = await this.identifySlowQueries();
    
    for (const query of slowQueries) {
      const optimization = await this.optimizeQuery(query);
      optimizations.push(optimization);
    }

    // Create missing indexes
    const missingIndexes = await this.identifyMissingIndexes();
    for (const index of missingIndexes) {
      await this.createIndex(index);
    }

    // Optimize table statistics
    await this.updateTableStatistics();

    return {
      optimizations,
      performanceImprovement: await this.measurePerformanceImprovement(),
      recommendedIndexes: missingIndexes,
      queryPlanImprovements: optimizations.map(o => o.planImprovement)
    };
  }

  private async identifySlowQueries(): Promise<SlowQuery[]> {
    const result = await pool.query(`
      SELECT 
        query,
        calls,
        total_time,
        mean_time,
        rows,
        100.0 * shared_blks_hit / nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent
      FROM pg_stat_statements
      WHERE mean_time > 100 -- Queries taking more than 100ms on average
      ORDER BY total_time DESC
      LIMIT 20
    `);

    return result.rows.map(row => ({
      query: row.query,
      calls: row.calls,
      totalTime: row.total_time,
      meanTime: row.mean_time,
      hitPercent: row.hit_percent
    }));
  }

  private async optimizeQuery(query: SlowQuery): Promise<QueryOptimization> {
    // Analyze query execution plan
    const plan = await this.getQueryPlan(query.query);
    
    // Identify optimization opportunities
    const opportunities = this.identifyOptimizationOpportunities(plan);
    
    // Generate optimized query
    const optimizedQuery = await this.generateOptimizedQuery(query.query, opportunities);
    
    return {
      originalQuery: query.query,
      optimizedQuery,
      expectedImprovement: opportunities.expectedImprovement,
      planImprovement: opportunities.planChanges,
      indexRecommendations: opportunities.recommendedIndexes
    };
  }
}

class CachingService {
  private redis: Redis;
  private memoryCache: Map<string, CacheEntry>;

  constructor() {
    this.redis = new Redis(process.env.REDIS_URL);
    this.memoryCache = new Map();
  }

  async get<T>(key: string, fallback?: () => Promise<T>): Promise<T | null> {
    // Try memory cache first (fastest)
    const memoryEntry = this.memoryCache.get(key);
    if (memoryEntry && !this.isExpired(memoryEntry)) {
      return memoryEntry.data;
    }

    // Try Redis cache (fast)
    const redisData = await this.redis.get(key);
    if (redisData) {
      const parsed = JSON.parse(redisData);
      // Update memory cache
      this.memoryCache.set(key, {
        data: parsed,
        expiresAt: new Date(Date.now() + 60000) // 1 minute memory cache
      });
      return parsed;
    }

    // Use fallback if provided
    if (fallback) {
      const data = await fallback();
      await this.set(key, data, 300); // 5 minutes Redis cache
      return data;
    }

    return null;
  }

  async set(key: string, data: any, ttlSeconds: number = 300): Promise<void> {
    // Set in Redis with TTL
    await this.redis.setex(key, ttlSeconds, JSON.stringify(data));
    
    // Set in memory cache with shorter TTL
    this.memoryCache.set(key, {
      data,
      expiresAt: new Date(Date.now() + Math.min(ttlSeconds * 1000, 60000))
    });
  }

  async invalidatePattern(pattern: string): Promise<void> {
    // Invalidate Redis keys matching pattern
    const keys = await this.redis.keys(pattern);
    if (keys.length > 0) {
      await this.redis.del(...keys);
    }

    // Invalidate memory cache entries
    for (const [key] of this.memoryCache) {
      if (this.matchesPattern(key, pattern)) {
        this.memoryCache.delete(key);
      }
    }
  }

  // Smart caching for dashboard metrics
  async getCachedDashboardMetrics(filters: DashboardFilters): Promise<DashboardMetrics | null> {
    const cacheKey = `dashboard:${this.hashFilters(filters)}`;
    
    return this.get(cacheKey, async () => {
      const metrics = await this.calculateDashboardMetrics(filters);
      return metrics;
    });
  }
}

// Advanced monitoring and alerting
class PerformanceMonitoringService {
  private metrics: Map<string, PerformanceMetric[]> = new Map();
  private alerts: AlertingService;

  constructor() {
    this.alerts = new AlertingService();
    this.startMonitoring();
  }

  private startMonitoring(): void {
    // Monitor API response times
    setInterval(() => this.monitorAPIPerformance(), 30000);
    
    // Monitor database performance
    setInterval(() => this.monitorDatabasePerformance(), 60000);
    
    // Monitor system resources
    setInterval(() => this.monitorSystemResources(), 30000);
    
    // Generate performance reports
    setInterval(() => this.generatePerformanceReport(), 3600000); // Hourly
  }

  async monitorAPIPerformance(): Promise<void> {
    const endpoints = [
      '/api/v1/employees',
      '/api/v1/projects',
      '/api/v1/attendance',
      '/api/v1/financials/dashboard'
    ];

    for (const endpoint of endpoints) {
      const startTime = performance.now();
      
      try {
        await this.testEndpoint(endpoint);
        const responseTime = performance.now() - startTime;
        
        this.recordMetric('api_response_time', endpoint, responseTime);
        
        // Alert if response time exceeds threshold
        if (responseTime > 1000) { // 1 second threshold
          await this.alerts.sendAlert({
            type: 'performance',
            severity: 'warning',
            message: `Slow API response: ${endpoint} took ${responseTime.toFixed(2)}ms`,
            endpoint,
            responseTime
          });
        }
      } catch (error) {
        await this.alerts.sendAlert({
          type: 'availability',
          severity: 'critical',
          message: `API endpoint failed: ${endpoint}`,
          endpoint,
          error: error.message
        });
      }
    }
  }

  async monitorDatabasePerformance(): Promise<void> {
    // Monitor connection pool
    const poolStats = await this.getPoolStatistics();
    this.recordMetric('db_connections', 'active', poolStats.activeConnections);
    this.recordMetric('db_connections', 'idle', poolStats.idleConnections);

    // Monitor query performance
    const queryStats = await this.getQueryStatistics();
    this.recordMetric('db_query_time', 'average', queryStats.averageTime);
    this.recordMetric('db_query_time', 'max', queryStats.maxTime);

    // Alert on performance issues
    if (poolStats.activeConnections > 15) { // 75% of max connections
      await this.alerts.sendAlert({
        type: 'database',
        severity: 'warning',
        message: 'High database connection usage',
        activeConnections: poolStats.activeConnections,
        maxConnections: 20
      });
    }
  }
}
```

### 4.4 Production Deployment

#### 4.4.1 Advanced Deployment Strategy
```typescript
// Comprehensive deployment and infrastructure management
interface ProductionDeployment {
  infrastructure: InfrastructureAsCode;
  cicd: CICDPipeline;
  monitoring: ProductionMonitoring;
  backup: BackupStrategy;
  scaling: AutoScalingService;
  security: ProductionSecurity;
}

// Infrastructure as Code with Terraform
const infrastructureConfig = `
# Enhanced AWS infrastructure configuration
provider "aws" {
  region = var.aws_region
}

# VPC and networking
resource "aws_vpc" "main" {
  cidr_block           = "10.0.0.0/16"
  enable_dns_hostnames = true
  enable_dns_support   = true

  tags = {
    Name = "HRMS-workforce-vpc"
    Environment = var.environment
  }
}

# Application Load Balancer
resource "aws_lb" "main" {
  name               = "HRMS-workforce-alb"
  internal           = false
  load_balancer_type = "application"
  security_groups    = [aws_security_group.alb.id]
  subnets           = aws_subnet.public[*].id

  enable_deletion_protection = true

  access_logs {
    bucket  = aws_s3_bucket.alb_logs.bucket
    prefix  = "alb"
    enabled = true
  }
}

# ECS Cluster for containerized applications
resource "aws_ecs_cluster" "main" {
  name = "HRMS-workforce-cluster"

  capacity_providers = ["FARGATE", "FARGATE_SPOT"]

  default_capacity_provider_strategy {
    capacity_provider = "FARGATE"
    weight           = 1
  }

  setting {
    name  = "containerInsights"
    value = "enabled"
  }
}

# RDS PostgreSQL with Multi-AZ
resource "aws_db_instance" "main" {
  identifier = "HRMS-workforce-db"

  engine         = "postgres"
  engine_version = "14.9"
  instance_class = "db.r6g.xlarge"

  allocated_storage     = 100
  max_allocated_storage = 1000
  storage_type         = "gp3"
  storage_encrypted    = true

  db_name  = "workforce"
  username = var.db_username
  password = var.db_password

  multi_az               = true
  backup_retention_period = 30
  backup_window          = "03:00-04:00"
  maintenance_window     = "sun:04:00-sun:05:00"

  skip_final_snapshot = false
  final_snapshot_identifier = "HRMS-workforce-final-snapshot"

  performance_insights_enabled = true
  monitoring_interval         = 60
  monitoring_role_arn        = aws_iam_role.rds_monitoring.arn

  tags = {
    Name = "HRMS-workforce-database"
    Environment = var.environment
  }
}

# ElastiCache Redis for caching
resource "aws_elasticache_replication_group" "main" {
  replication_group_id       = "HRMS-workforce-redis"
  description                = "Redis cluster for workforce management"

  node_type            = "cache.r6g.large"
  port                 = 6379
  parameter_group_name = "default.redis7"

  num_cache_clusters = 2
  multi_az_enabled   = true

  subnet_group_name = aws_elasticache_subnet_group.main.name
  security_group_ids = [aws_security_group.redis.id]

  at_rest_encryption_enabled = true
  transit_encryption_enabled = true

  automatic_failover_enabled = true
  auto_minor_version_upgrade = true

  tags = {
    Name = "HRMS-workforce-redis"
    Environment = var.environment
  }
}
`;

// Advanced CI/CD pipeline
const cicdPipeline = `
# GitHub Actions workflow for comprehensive CI/CD
name: Production Deployment Pipeline

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  NODE_VERSION: '18'
  POSTGRES_VERSION: '14'

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: workforce_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: \${{ env.NODE_VERSION }}
        cache: 'npm'
    
    - name: Install dependencies
      run: |
        npm ci
        npm run build
    
    - name: Run linting
      run: npm run lint
    
    - name: Run type checking
      run: npm run type-check
    
    - name: Run unit tests
      run: npm run test:unit -- --coverage
    
    - name: Run integration tests
      run: npm run test:integration
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/workforce_test
        REDIS_URL: redis://localhost:6379
    
    - name: Run E2E tests
      run: npm run test:e2e
    
    - name: Security scan
      run: npm audit --audit-level high
    
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3

  build:
    needs: test
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: \${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: \${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1
    
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v1
    
    - name: Build and push Docker images
      env:
        ECR_REGISTRY: \${{ steps.login-ecr.outputs.registry }}
        ECR_REPOSITORY: HRMS-workforce
        IMAGE_TAG: \${{ github.sha }}
      run: |
        # Build backend image
        docker build -t \$ECR_REGISTRY/\$ECR_REPOSITORY-backend:\$IMAGE_TAG ./backend
        docker push \$ECR_REGISTRY/\$ECR_REPOSITORY-backend:\$IMAGE_TAG
        
        # Build frontend image
        docker build -t \$ECR_REGISTRY/\$ECR_REPOSITORY-frontend:\$IMAGE_TAG ./frontend
        docker push \$ECR_REGISTRY/\$ECR_REPOSITORY-frontend:\$IMAGE_TAG

  deploy-staging:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Deploy to staging
      run: |
        # Deploy using AWS ECS
        aws ecs update-service --cluster staging-cluster --service workforce-backend --force-new-deployment
        aws ecs update-service --cluster staging-cluster --service workforce-frontend --force-new-deployment
    
    - name: Run smoke tests
      run: npm run test:smoke -- --env=staging
    
    - name: Performance testing
      run: npm run test:performance -- --env=staging

  deploy-production:
    needs: deploy-staging
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production
    
    steps:
    - name: Blue-Green deployment
      run: |
        # Implement blue-green deployment strategy
        ./scripts/blue-green-deploy.sh production \${{ github.sha }}
    
    - name: Health checks
      run: |
        # Comprehensive health checks
        ./scripts/health-check.sh production
    
    - name: Rollback on failure
      if: failure()
      run: |
        ./scripts/rollback.sh production
`;

// Production monitoring and alerting
class ProductionMonitoringService {
  private cloudWatch: CloudWatchService;
  private datadog: DatadogService;
  private alertManager: AlertManagerService;

  async setupMonitoring(): Promise<void> {
    // Application Performance Monitoring (APM)
    await this.setupAPMMonitoring();
    
    // Infrastructure monitoring
    await this.setupInfrastructureMonitoring();
    
    // Business metrics monitoring
    await this.setupBusinessMetricsMonitoring();
    
    // Log aggregation and analysis
    await this.setupLogMonitoring();
    
    // Synthetic monitoring
    await this.setupSyntheticMonitoring();
  }

  private async setupAPMMonitoring(): Promise<void> {
    const apmConfig = {
      // API endpoint monitoring
      endpoints: [
        { path: '/api/v1/employees', sla: { responseTime: 500, availability: 99.9 } },
        { path: '/api/v1/attendance', sla: { responseTime: 300, availability: 99.9 } },
        { path: '/api/v1/financials/dashboard', sla: { responseTime: 1000, availability: 99.5 } }
      ],
      
      // Database monitoring
      database: {
        connectionPool: { maxConnections: 20, alertThreshold: 15 },
        queryPerformance: { slowQueryThreshold: 1000, alertThreshold: 5 },
        deadlocks: { alertOnAny: true }
      },
      
      // Memory and CPU monitoring
      resources: {
        memory: { alertThreshold: 85 }, // 85% memory usage
        cpu: { alertThreshold: 80 }, // 80% CPU usage
        disk: { alertThreshold: 90 } // 90% disk usage
      }
    };

    await this.cloudWatch.createDashboard('workforce-apm', apmConfig);
    await this.setupAlerts(apmConfig);
  }

  private async setupBusinessMetricsMonitoring(): Promise<void> {
    // Custom business metrics
    const businessMetrics = [
      {
        name: 'daily_profit_margin',
        query: 'SELECT AVG(profit_margin) FROM financial_calculations WHERE calculation_date = CURRENT_DATE',
        threshold: { min: 15, max: 50 },
        alertOnOutOfRange: true
      },
      {
        name: 'attendance_rate',
        query: 'SELECT (COUNT(*)::DECIMAL / (SELECT COUNT(*) FROM employees WHERE status = \'active\')) * 100 FROM attendance_records WHERE date = CURRENT_DATE',
        threshold: { min: 85 },
        alertOnBelow: true
      },
      {
        name: 'document_expiry_alerts',
        query: 'SELECT COUNT(*) FROM employee_documents WHERE expiry_date <= CURRENT_DATE + INTERVAL \'30 days\'',
        threshold: { max: 10 },
        alertOnAbove: true
      }
    ];

    for (const metric of businessMetrics) {
      await this.scheduleMetricCollection(metric);
    }
  }
}
```

---

## Enhanced Features & Innovations

### Advanced AI-Powered Features

#### Intelligent Workforce Optimization
```typescript
// Advanced AI-driven workforce optimization
class IntelligentWorkforceOptimizer {
  async optimizeWorkforceAllocation(): Promise<OptimizationRecommendation[]> {
    const recommendations: OptimizationRecommendation[] = [];

    // Analyze current allocation efficiency
    const currentEfficiency = await this.analyzeCurrentAllocation();
    
    // Identify optimization opportunities
    const opportunities = await this.identifyOptimizationOpportunities();
    
    // Generate specific recommendations
    for (const opportunity of opportunities) {
      const recommendation = await this.generateRecommendation(opportunity);
      recommendations.push(recommendation);
    }

    return recommendations.sort((a, b) => b.expectedImpact - a.expectedImpact);
  }

  private async generateRecommendation(opportunity: OptimizationOpportunity): Promise<OptimizationRecommendation> {
    return {
      id: uuid.v4(),
      type: opportunity.type,
      title: opportunity.title,
      description: opportunity.description,
      currentState: opportunity.currentMetrics,
      proposedState: opportunity.optimizedMetrics,
      expectedImpact: opportunity.expectedImpact,
      implementationSteps: opportunity.actionPlan,
      riskAssessment: await this.assessImplementationRisk(opportunity),
      timeframe: opportunity.estimatedTimeframe,
      resourceRequirements: opportunity.resourceNeeds,
      successMetrics: opportunity.kpis
    };
  }
}

// Predictive maintenance for equipment and workforce
class PredictiveMaintenanceService {
  async predictEquipmentMaintenance(): Promise<MaintenancePrediction[]> {
    const equipment = await this.getEquipmentData();
    const predictions: MaintenancePrediction[] = [];

    for (const item of equipment) {
      const usageData = await this.getEquipmentUsageData(item.id);
      const prediction = await this.mlModels.equipmentMaintenance.predict(usageData);
      
      predictions.push({
        equipmentId: item.id,
        equipmentName: item.name,
        predictedMaintenanceDate: prediction.maintenanceDate,
        confidence: prediction.confidence,
        maintenanceType: prediction.type,
        estimatedCost: prediction.cost,
        riskOfFailure: prediction.failureRisk,
        recommendedActions: prediction.actions
      });
    }

    return predictions;
  }

  async predictWorkforceNeeds(): Promise<WorkforcePrediction[]> {
    const projects = await this.getActiveProjects();
    const predictions: WorkforcePrediction[] = [];

    for (const project of projects) {
      const historicalData = await this.getProjectWorkforceData(project.id);
      const prediction = await this.mlModels.workforceNeeds.predict(historicalData);
      
      predictions.push({
        projectId: project.id,
        projectName: project.name,
        currentWorkforce: project.assignedWorkers,
        predictedNeeds: prediction.workforceRequirement,
        skillGaps: prediction.identifiedSkillGaps,
        hiringRecommendations: prediction.hiringPlan,
        timeframe: prediction.timeframe,
        confidence: prediction.confidence
      });
    }

    return predictions;
  }
}
```

### Advanced Security Features

#### Zero-Trust Security Architecture
```typescript
// Comprehensive zero-trust security implementation
class ZeroTrustSecurityService {
  async implementZeroTrustArchitecture(): Promise<ZeroTrustConfig> {
    return {
      // Identity verification
      identityVerification: {
        multiFactorAuthentication: true,
        biometricAuthentication: true,
        deviceTrustVerification: true,
        continuousAuthentication: true
      },
      
      // Network security
      networkSecurity: {
        microsegmentation: true,
        encryptedCommunication: true,
        networkAccessControl: true,
        trafficInspection: true
      },
      
      // Data protection
      dataProtection: {
        endToEndEncryption: true,
        dataClassification: true,
        accessLogging: true,
        dataLossPrevention: true
      },
      
      // Application security
      applicationSecurity: {
        runtimeProtection: true,
        vulnerabilityScanning: true,
        codeAnalysis: true,
        behaviorAnalysis: true
      }
    };
  }

  async verifyUserAccess(request: AccessRequest): Promise<AccessDecision> {
    const verificationSteps: VerificationStep[] = [];

    // Step 1: Identity verification
    const identityVerification = await this.verifyIdentity(request.user);
    verificationSteps.push(identityVerification);

    // Step 2: Device trust verification
    const deviceVerification = await this.verifyDevice(request.device);
    verificationSteps.push(deviceVerification);

    // Step 3: Location verification
    const locationVerification = await this.verifyLocation(request.location);
    verificationSteps.push(locationVerification);

    // Step 4: Behavioral analysis
    const behaviorVerification = await this.analyzeBehavior(request.user, request.action);
    verificationSteps.push(behaviorVerification);

    // Step 5: Risk assessment
    const riskAssessment = await this.assessRisk(verificationSteps);

    return {
      decision: riskAssessment.riskLevel <= 'medium' ? 'allow' : 'deny',
      riskLevel: riskAssessment.riskLevel,
      verificationSteps,
      additionalRequirements: riskAssessment.additionalRequirements,
      sessionDuration: this.calculateSessionDuration(riskAssessment),
      auditTrail: await this.createAuditTrail(request, verificationSteps)
    };
  }
}
```

---

## Resource Requirements & Timeline

### Enhanced Resource Allocation

#### Phase 1: Backend Foundation (4 weeks) - $45,000
```typescript
interface Phase1Resources {
  personnel: {
    seniorBackendDeveloper: {
      duration: '4 weeks';
      rate: '$90/hour';
      hours: 160;
      cost: '$14,400';
      responsibilities: [
        'Database architecture and implementation',
        'RESTful API development',
        'Authentication system design',
        'Performance optimization'
      ];
    };
    
    databaseAdministrator: {
      duration: '4 weeks';
      rate: '$85/hour';
      hours: 120;
      cost: '$10,200';
      responsibilities: [
        'Database schema design',
        'Performance tuning',
        'Backup and recovery setup',
        'Security configuration'
      ];
    };
    
    devOpsEngineer: {
      duration: '4 weeks';
      rate: '$95/hour';
      hours: 100;
      cost: '$9,500';
      responsibilities: [
        'Infrastructure setup',
        'CI/CD pipeline configuration',
        'Monitoring implementation',
        'Security hardening'
      ];
    };
    
    fullStackDeveloper: {
      duration: '4 weeks';
      rate: '$80/hour';
      hours: 140;
      cost: '$11,200';
      responsibilities: [
        'Frontend API integration',
        'Data migration implementation',
        'Testing framework setup',
        'Documentation'
      ];
    };
  };
  
  infrastructure: {
    developmentEnvironment: '$2,000';
    testingEnvironment: '$1,500';
    toolsAndLicenses: '$3,000';
    securityTools: '$2,000';
  };
  
  totalCost: '$53,800';
}
```

#### Phase 2: Real-time Features (4 weeks) - $35,000
```typescript
interface Phase2Resources {
  personnel: {
    seniorFullStackDeveloper: {
      duration: '4 weeks';
      rate: '$85/hour';
      hours: 160;
      cost: '$13,600';
      responsibilities: [
        'WebSocket implementation',
        'Real-time dashboard development',
        'Collaborative features',
        'Performance optimization'
      ];
    };
    
    frontendSpecialist: {
      duration: '4 weeks';
      rate: '$75/hour';
      hours: 140;
      cost: '$10,500';
      responsibilities: [
        'Real-time UI components',
        'State management optimization',
        'User experience enhancement',
        'Mobile responsiveness'
      ];
    };
    
    backendDeveloper: {
      duration: '4 weeks';
      rate: '$80/hour';
      hours: 120;
      cost: '$9,600';
      responsibilities: [
        'WebSocket server implementation',
        'Real-time data processing',
        'Caching optimization',
        'API enhancement'
      ];
    };
  };
  
  infrastructure: {
    redisCluster: '$800';
    websocketInfrastructure: '$600';
    monitoringTools: '$500';
  };
  
  totalCost: '$35,000';
}
```

#### Phase 3: Mobile & AI (4 weeks) - $60,000
```typescript
interface Phase3Resources {
  personnel: {
    mobileAppDeveloper: {
      duration: '4 weeks';
      rate: '$90/hour';
      hours: 160;
      cost: '$14,400';
      responsibilities: [
        'React Native app development',
        'Offline functionality',
        'Push notifications',
        'App store deployment'
      ];
    };
    
    aiMlEngineer: {
      duration: '4 weeks';
      rate: '$120/hour';
      hours: 140;
      cost: '$16,800';
      responsibilities: [
        'ML model development',
        'Predictive analytics',
        'AI insights engine',
        'Model deployment'
      ];
    };
    
    dataScientist: {
      duration: '4 weeks';
      rate: '$110/hour';
      hours: 120;
      cost: '$13,200';
      responsibilities: [
        'Data analysis and modeling',
        'Feature engineering',
        'Model validation',
        'Business intelligence'
      ];
    };
    
    backendDeveloper: {
      duration: '4 weeks';
      rate: '$80/hour';
      hours: 100;
      cost: '$8,000';
      responsibilities: [
        'AI service integration',
        'Mobile API development',
        'Performance optimization',
        'Data pipeline implementation'
      ];
    };
  };
  
  infrastructure: {
    mlInfrastructure: '$3,000';
    mobileTestingDevices: '$2,000';
    aiServices: '$2,600';
  };
  
  totalCost: '$60,000';
}
```

#### Phase 4: Production Readiness (4 weeks) - $30,000
```typescript
interface Phase4Resources {
  personnel: {
    qaEngineer: {
      duration: '4 weeks';
      rate: '$70/hour';
      hours: 160;
      cost: '$11,200';
      responsibilities: [
        'Comprehensive testing',
        'Test automation',
        'Performance testing',
        'Security testing'
      ];
    };
    
    securitySpecialist: {
      duration: '4 weeks';
      rate: '$100/hour';
      hours: 80;
      cost: '$8,000';
      responsibilities: [
        'Security audit',
        'Penetration testing',
        'Compliance verification',
        'Security documentation'
      ];
    };
    
    devOpsEngineer: {
      duration: '4 weeks';
      rate: '$95/hour';
      hours: 100;
      cost: '$9,500';
      responsibilities: [
        'Production deployment',
        'Monitoring setup',
        'Backup configuration',
        'Disaster recovery'
      ];
    };
  };
  
  infrastructure: {
    productionEnvironment: '$5,000';
    securityTools: '$3,000';
    monitoringLicenses: '$2,000';
    backupSolution: '$1,300';
  };
  
  totalCost: '$40,000';
}
```

---

## Success Metrics & KPIs

### Enhanced Success Criteria
```typescript
interface EnhancedSuccessMetrics {
  technical: {
    performance: {
      apiResponseTime: '<200ms (95th percentile)';
      databaseQueryTime: '<50ms (average)';
      pageLoadTime: '<1.5 seconds';
      systemUptime: '99.95%';
      errorRate: '<0.1%';
    };
    
    scalability: {
      concurrentUsers: '1,000+ simultaneous users';
      dataVolume: '10M+ records efficiently processed';
      transactionThroughput: '10,000+ transactions/minute';
      autoScaling: 'Automatic scaling based on load';
    };
    
    security: {
      vulnerabilities: '0 critical, <3 medium';
      penetrationTestScore: '>95%';
      complianceScore: '100%';
      auditTrailCompleteness: '100%';
    };
  };
  
  business: {
    userAdoption: {
      activeUserRate: '>95% within 3 months';
      featureUtilization: '>85% of core features';
      userSatisfaction: '>4.7/5.0';
      supportTicketReduction: '>60%';
    };
    
    operationalEfficiency: {
      processAutomation: '>80% of manual processes automated';
      dataAccuracy: '>99.5%';
      reportGenerationTime: '<5 minutes for complex reports';
      decisionMakingSpeed: '>50% faster';
    };
    
    financialImpact: {
      costSavings: '>$200,000 annually';
      revenueIncrease: '>$150,000 annually';
      roi: '>300% over 3 years';
      paybackPeriod: '<8 months';
    };
  };
  
  compliance: {
    saudiLaborLaw: '100% compliance';
    dataProtection: '100% GDPR/local compliance';
    financialReporting: '100% accuracy';
    auditReadiness: 'Continuous audit readiness';
  };
}
```

---

## Risk Mitigation & Contingency Planning

### Enhanced Risk Management
```typescript
interface EnhancedRiskManagement {
  technicalRisks: {
    dataLoss: {
      probability: 'Low';
      impact: 'Critical';
      mitigation: [
        'Automated daily backups with 30-day retention',
        'Real-time replication to secondary region',
        'Point-in-time recovery capability',
        'Disaster recovery testing quarterly'
      ];
      contingency: 'Complete system restoration within 4 hours';
      cost: '$8,000';
    };
    
    performanceBottlenecks: {
      probability: 'Medium';
      impact: 'High';
      mitigation: [
        'Comprehensive load testing before deployment',
        'Auto-scaling infrastructure',
        'Performance monitoring with alerts',
        'Database query optimization'
      ];
      contingency: 'Horizontal scaling and optimization within 2 hours';
      cost: '$5,000';
    };
    
    securityBreaches: {
      probability: 'Low';
      impact: 'Critical';
      mitigation: [
        'Zero-trust security architecture',
        'Regular security audits and penetration testing',
        'Real-time threat detection',
        'Employee security training'
      ];
      contingency: 'Incident response plan with 1-hour response time';
      cost: '$12,000';
    };
  };
  
  businessRisks: {
    userAdoptionFailure: {
      probability: 'Medium';
      impact: 'High';
      mitigation: [
        'Comprehensive user training program',
        'Phased rollout with feedback collection',
        'Change management support',
        'User experience optimization'
      ];
      contingency: 'Enhanced training and support program';
      cost: '$10,000';
    };
    
    scopeCreep: {
      probability: 'High';
      impact: 'Medium';
      mitigation: [
        'Formal change control process',
        'Regular stakeholder reviews',
        'Clear requirement documentation',
        'Agile development methodology'
      ];
      contingency: 'Additional development resources';
      cost: '$15,000';
    };
  };
}
```

This enhanced development plan provides a comprehensive roadmap for transforming the HRMS workforce management system into a world-class, production-ready platform with advanced AI capabilities, robust security, and enterprise-grade scalability.